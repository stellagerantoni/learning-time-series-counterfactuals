{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellagerantoni/learning-time-series-counterfactuals/blob/main/multivariate_pendigits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIiG4khZBur-",
        "outputId": "e4076bb4-241c-49ce-c2a7-07068fe9592d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 336 (delta 136), reused 168 (delta 120), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (336/336), 5.52 MiB | 11.27 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "/content/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        "%cd learning-time-series-counterfactuals/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw\n",
        "!pip install aeon[all_extras]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89L3kts7CCan",
        "outputId": "99e11111-501e-42cd-bfa8-b564150a6b12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aeon[all_extras]\n",
            "  Downloading aeon-0.4.0-py3-none-any.whl (39.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.0/39.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (23.1.0)\n",
            "Collecting deprecated>=1.2.13 (from aeon[all_extras])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (0.56.4)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (23.1)\n",
            "Requirement already satisfied: pandas<2.1.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.3.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.11.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (2.2.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (2023.8.1)\n",
            "Collecting filterpy>=1.4.5 (from aeon[all_extras])\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (3.9.0)\n",
            "Collecting hmmlearn>=0.2.7 (from aeon[all_extras])\n",
            "  Downloading hmmlearn-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gluonts>=0.12.4 (from aeon[all_extras])\n",
            "  Downloading gluonts-0.13.4-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.1/812.1 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-self-attention (from aeon[all_extras])\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kotsu>=0.3.1 (from aeon[all_extras])\n",
            "  Downloading kotsu-0.3.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (3.7.1)\n",
            "Collecting mne (from aeon[all_extras])\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima<3.0.0,>=1.8.0 (from aeon[all_extras])\n",
            "  Downloading pmdarima-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prophet>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.1.4)\n",
            "Collecting pyod>=0.8.0 (from aeon[all_extras])\n",
            "  Downloading pyod-1.1.0.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-posthocs>=0.6.5 (from aeon[all_extras])\n",
            "  Downloading scikit_posthocs-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (0.12.2)\n",
            "Collecting statsforecast>=0.5.2 (from aeon[all_extras])\n",
            "  Downloading statsforecast-1.6.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (0.14.0)\n",
            "Requirement already satisfied: stumpy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (1.12.0)\n",
            "Collecting tbats>=1.1.0 (from aeon[all_extras])\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.13.0 (from aeon[all_extras])\n",
            "  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability<0.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (0.20.1)\n",
            "Collecting tsfresh>=0.20.0 (from aeon[all_extras])\n",
            "  Downloading tsfresh-0.20.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tslearn<0.6.0,>=0.5.2 (from aeon[all_extras])\n",
            "  Downloading tslearn-0.5.3.2-py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.2/358.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from aeon[all_extras]) (2023.7.0)\n",
            "Collecting mlflow<2.4.0 (from aeon[all_extras])\n",
            "  Downloading mlflow-2.3.2-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting esig<0.9.8.3,>=0.9.7 (from aeon[all_extras])\n",
            "  Downloading esig-0.9.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon[all_extras]) (1.15.0)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts>=0.12.4->aeon[all_extras]) (1.10.12)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.10/dist-packages (from gluonts>=0.12.4->aeon[all_extras]) (4.66.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts>=0.12.4->aeon[all_extras]) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts>=0.12.4->aeon[all_extras]) (4.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->aeon[all_extras]) (2.8.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (8.1.7)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (2.31.0)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (2.2.5)\n",
            "Collecting querystring-parser<2 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (2.0.20)\n",
            "Requirement already satisfied: pyarrow<12,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (3.4.4)\n",
            "Collecting gunicorn<21 (from mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow<2.4.0->aeon[all_extras]) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->aeon[all_extras]) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->aeon[all_extras]) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pmdarima<3.0.0,>=1.8.0->aeon[all_extras]) (1.3.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima<3.0.0,>=1.8.0->aeon[all_extras]) (3.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima<3.0.0,>=1.8.0->aeon[all_extras]) (2.0.4)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet>=1.1.0->aeon[all_extras]) (1.1.0)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from prophet>=1.1.0->aeon[all_extras]) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from prophet>=1.1.0->aeon[all_extras]) (2.4.0)\n",
            "Requirement already satisfied: holidays>=0.25 in /usr/local/lib/python3.10/dist-packages (from prophet>=1.1.0->aeon[all_extras]) (0.32)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from prophet>=1.1.0->aeon[all_extras]) (6.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod>=0.8.0->aeon[all_extras]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0,>=1.0.0->aeon[all_extras]) (3.2.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (from statsforecast>=0.5.2->aeon[all_extras]) (0.17.3)\n",
            "Collecting fugue>=0.8.1 (from statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading fugue-0.8.6-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.0/275.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.1->aeon[all_extras]) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (1.57.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (0.4.14)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow<2.13.0->aeon[all_extras])\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (3.3.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow<2.13.0->aeon[all_extras])\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow<2.13.0->aeon[all_extras])\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (2.3.0)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->aeon[all_extras])\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13.0->aeon[all_extras]) (0.33.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.21.0->aeon[all_extras]) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.21.0->aeon[all_extras]) (0.1.8)\n",
            "Requirement already satisfied: distributed>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh>=0.20.0->aeon[all_extras]) (2023.8.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->aeon[all_extras]) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask->aeon[all_extras]) (1.4.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->aeon[all_extras]) (1.7.0)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13.0->aeon[all_extras]) (0.41.2)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from convertdate>=2.1.2->prophet>=1.1.0->aeon[all_extras]) (0.5.12)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<2.4.0->aeon[all_extras]) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<2.4.0->aeon[all_extras]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow<2.4.0->aeon[all_extras]) (0.9.0)\n",
            "Collecting urllib3 (from pmdarima<3.0.0,>=1.8.0->aeon[all_extras])\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (1.0.5)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (2.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (6.3.2)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.11.0->tsfresh>=0.20.0->aeon[all_extras]) (3.0.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow<2.4.0->aeon[all_extras]) (1.6.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow<2.4.0->aeon[all_extras]) (2.3.7)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow<2.4.0->aeon[all_extras]) (2.1.2)\n",
            "Collecting triad>=0.9.1 (from fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading triad-0.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
            "Collecting qpd>=0.4.4 (from fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading qpd-0.4.4-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fugue-sql-antlr>=0.1.6 (from fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading fugue-sql-antlr-0.1.6.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.6/154.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sqlglot (from fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading sqlglot-18.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.2/303.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow<2.4.0->aeon[all_extras]) (3.16.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13.0->aeon[all_extras]) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow<2.4.0->aeon[all_extras]) (2.1.3)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.10/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.1.0->aeon[all_extras]) (4.1.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->aeon[all_extras]) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow<2.4.0->aeon[all_extras]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow<2.4.0->aeon[all_extras]) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow<2.4.0->aeon[all_extras]) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow<2.4.0->aeon[all_extras]) (2.0.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (0.7.1)\n",
            "Collecting antlr4-python3-runtime<4.12,>=4.11.1 (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow<2.4.0->aeon[all_extras])\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (1.3.1)\n",
            "Collecting fs (from triad>=0.9.1->fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras])\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13.0->aeon[all_extras]) (0.5.0)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->triad>=0.9.1->fugue>=0.8.1->statsforecast>=0.5.2->aeon[all_extras]) (1.4.4)\n",
            "Building wheels for collected packages: filterpy, pyod, keras-self-attention, databricks-cli, fugue-sql-antlr\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=47b46867a184f72a7108c7d66aa5af80c88f28b9ed39af1b1291e675c63caf6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.1.0-py3-none-any.whl size=185329 sha256=22a0f96ee92f897a9e0e0df7f848caa65a2c34fe8702c6545cf98ebab2b7541c\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/8e/e2/e932956b10b843eb6be9eefa70b5c1bee7b561be14c423b136\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=3f1ac5b2e58b2474161be8b21f721556f1c6da57f69bd95b1ccde1f6c801b867\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143855 sha256=9d709ce08ea625c7ebac61d54abcf8245169a3b72d6d7de944940eedfa53a2fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/63/93/5402c1a09c1868a59d0b05013484e07af97a9d7b3dbd5bd39a\n",
            "  Building wheel for fugue-sql-antlr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fugue-sql-antlr: filename=fugue_sql_antlr-0.1.6-py3-none-any.whl size=158045 sha256=7b9a2923b307a1a9c9ff6af57a84bfe2bf992b7b81224a68a3b112ef68be903c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/54/a1/b294b8b33c6107946b5720b3acb1fce07b97bbbc9677a501ce\n",
            "Successfully built filterpy pyod keras-self-attention databricks-cli fugue-sql-antlr\n",
            "Installing collected packages: antlr4-python3-runtime, wrapt, urllib3, tensorflow-estimator, sqlglot, smmap, querystring-parser, Mako, keras-self-attention, keras, gunicorn, fs, esig, gitdb, deprecated, alembic, tslearn, triad, pyod, kotsu, hmmlearn, gluonts, gitpython, filterpy, docker, databricks-cli, aeon, scikit-posthocs, pmdarima, mne, mlflow, fugue-sql-antlr, adagio, tsfresh, tensorboard, tbats, qpd, tensorflow, fugue, statsforecast\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.13.0\n",
            "    Uninstalling tensorflow-estimator-2.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.13.0\n",
            "    Uninstalling tensorboard-2.13.0:\n",
            "      Successfully uninstalled tensorboard-2.13.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.13.0\n",
            "    Uninstalling tensorflow-2.13.0:\n",
            "      Successfully uninstalled tensorflow-2.13.0\n",
            "Successfully installed Mako-1.2.4 adagio-0.2.4 aeon-0.4.0 alembic-1.12.0 antlr4-python3-runtime-4.11.1 databricks-cli-0.17.7 deprecated-1.2.14 docker-6.1.3 esig-0.9.8.2 filterpy-1.4.5 fs-2.4.16 fugue-0.8.6 fugue-sql-antlr-0.1.6 gitdb-4.0.10 gitpython-3.1.36 gluonts-0.13.4 gunicorn-20.1.0 hmmlearn-0.3.0 keras-2.12.0 keras-self-attention-0.51.0 kotsu-0.3.3 mlflow-2.3.2 mne-1.5.1 pmdarima-2.0.3 pyod-1.1.0 qpd-0.4.4 querystring-parser-1.2.4 scikit-posthocs-0.7.0 smmap-5.0.0 sqlglot-18.5.0 statsforecast-1.6.0 tbats-1.1.3 tensorboard-2.12.3 tensorflow-2.12.1 tensorflow-estimator-2.12.0 triad-0.9.1 tsfresh-0.20.1 tslearn-0.5.3.2 urllib3-1.26.16 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "%cd src\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdkpan5lCGRH",
        "outputId": "e49279ef-c9bc-49db-ce7a-246ff00fd441"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "RANDOM_STATE = 39"
      ],
      "metadata": {
        "id": "GJE1AxFnE51S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FUNCTIONS**"
      ],
      "metadata": {
        "id": "IHBw9E_4Zm5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset):\n",
        "  X, y, meta_data = load_classification(dataset)\n",
        "  if dataset == 'Heartbeat':\n",
        "    pos = 'normal'\n",
        "    neg = 'abnormal'\n",
        "    X = X.transpose(0,2,1)\n",
        "  if dataset == 'SelfRegulationSCP1':\n",
        "    pos = 'positivity'\n",
        "    neg = 'negativity'\n",
        "    X = X.transpose(0,2,1)\n",
        "  if dataset == 'Cricket':\n",
        "    return X,y,meta_data\n",
        "  if dataset == 'SpokenArabicDigits':\n",
        "    return X,y,meta_data\n",
        "  if dataset == 'PenDigits':\n",
        "    return X,y,meta_data\n",
        "\n",
        "  print(\" Shape of X = \", X.shape)\n",
        "  print(\" Shape of y = \", y.shape)\n",
        "  print(\" Meta data = \", meta_data)\n",
        "  # Convert positive and negative labels to 1 and 0\n",
        "  pos_label, neg_label = 1, 0\n",
        "  if pos != pos_label:\n",
        "      y[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "  if neg != neg_label:\n",
        "      y[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "  y = y.astype(int)\n",
        "  print(f\"\\n X[:1] = \\n{X[:1]}\")\n",
        "  return X,y,pos_label, neg_label"
      ],
      "metadata": {
        "id": "QsJJktx22dXs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample, shuffle\n",
        "def upsample_minority(X, y, pos_label=1, neg_label=0, random_state=39):\n",
        "    # Get counts\n",
        "    ones = pd.value_counts(y_train)['1']\n",
        "    twos = pd.value_counts(y_train)['2']\n",
        "    threes = pd.value_counts(y_train)['3']\n",
        "    fours = pd.value_counts(y_train)['4']\n",
        "    fives = pd.value_counts(y_train)['5']\n",
        "    sixes = pd.value_counts(y_train)['6']\n",
        "    sevens = pd.value_counts(y_train)['7']\n",
        "    eights = pd.value_counts(y_train)['8']\n",
        "    nines = pd.value_counts(y_train)['9']\n",
        "    print(f'before upsampling: ones = {ones}, twos = {twos}, trees = {threes}, fours = {fours},fives = {fives},\\n sixes = {sixes}, sevens = {sevens}, eights = {eights}, nines = {nines}' )\n",
        "\n",
        "    # Divide by class\n",
        "    num_count.append(ones)\n",
        "    num_count.append(twos)\n",
        "    num_count.append(threes)\n",
        "    num_count.append(fours)\n",
        "    num_count.append(fives)\n",
        "    num_count.append(sixes)\n",
        "    num_count.append(sevens)\n",
        "    num_count.append(eights)\n",
        "    num_count.append(nines)\n",
        "\n",
        "    max_count = 0\n",
        "\n",
        "    for i in num_count:\n",
        "      if i > max_count:\n",
        "        max_count = i\n",
        "      elif i = max_count:\n",
        "        X = X\n",
        "    for i in range(9):\n",
        "      X_to_resample = X[y == i]\n",
        "      y_for_resampling = y[y == i]\n",
        "      X_to_resample = resample(y_for_resampling, replace=True, n_samples=max_count, random_state=random_state)\n",
        "\n",
        "      X_concat = np.concatenate([X_pos, X_neg_over], axis=0)\n",
        "      y_concat = np.array(\n",
        "            [pos_label for i in range(pos_counts)]\n",
        "            + [neg_label for j in range(pos_counts)]\n",
        "        )\n",
        "    # Shuffle the index after up-sampling\n",
        "    X_concat, y_concat = shuffle(X_concat, y_concat, random_state=random_state)\n",
        "\n",
        "    return X_concat, y_concat"
      ],
      "metadata": {
        "id": "SC9oo2lJE3ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(class_counts)\n",
        "unique_classes"
      ],
      "metadata": {
        "id": "A-LjTXm0NnJI",
        "outputId": "ce30dc64-0756-4a6b-d35d-98895e647391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[914 914 915 844 915 844 845 914 844 844]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample, shuffle\n",
        "def upsample_minority_multivariate(X, y, random_state=39):\n",
        "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "    max_count = max(class_counts)\n",
        "\n",
        "    X_resampled_list = []\n",
        "    y_resampled_list = []\n",
        "\n",
        "    for cls in unique_classes:\n",
        "        X_cls = X[y == cls]\n",
        "        y_cls = y[y == cls]\n",
        "\n",
        "        # Resample the current class data to match the max count\n",
        "        X_cls_resampled, y_cls_resampled = resample(X_cls, y_cls,\n",
        "                                                    replace=True, # sample with replacement (upsample)\n",
        "                                                    n_samples=max_count, # match the number in majority class\n",
        "                                                    random_state=random_state) # reproducible results\n",
        "\n",
        "        X_resampled_list.append(X_cls_resampled)\n",
        "        y_resampled_list.append(y_cls_resampled)\n",
        "\n",
        "    # Vertically stack the resampled data for each class\n",
        "    X_resampled = np.vstack(X_resampled_list)\n",
        "    y_resampled = np.hstack(y_resampled_list)\n",
        "    X_concat, y_concat = shuffle(X_resampled, y_resampled, random_state=random_state)\n",
        "\n",
        "    return X_resampled, y_resampled\n"
      ],
      "metadata": {
        "id": "FvSxYCqwNUWB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "rBe-rm7TOFuN",
        "outputId": "c341a5dc-f8dd-4e9d-f486-8d5150f4658d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[915 915 915 915 915 915 915 915 915 915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "print(f'y = {y_train[idx]}')\n",
        "x_coords = X_train[idx, 0]\n",
        "y_coords = X_train[idx,1]\n",
        "plt.figure(figsize=(5, 5))  # Adjust the figure size as needed\n",
        "plt.plot(x_coords, y_coords, marker='o', linestyle='-')\n",
        "plt.title(\"Handwritten Digit 3\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n0FkGfyDp3a6",
        "outputId": "27df1975-89e1-4041-c1a0-9cea052897e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = [0. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1]"
      ],
      "metadata": {
        "id": "QEJqkunWPzD8",
        "outputId": "96325f0e-8e10-474a-c8b5-9fd6f129c383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.,  27.,  42.,  29.,  15.,  37.,  69., 100.],\n",
              "       [ 89., 100.,  75.,  45.,  15.,   0.,   2.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def normalize_multivariate(data, n_timesteps, n_features, scaler=None):\n",
        "\n",
        "    # Then reshape data to have timesteps as rows for normalization\n",
        "    data_reshaped = data.reshape(-1, n_features)\n",
        "\n",
        "    if scaler is None:\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaler.fit(data_reshaped)\n",
        "\n",
        "    normalized = scaler.transform(data_reshaped)\n",
        "\n",
        "    # Return data reshaped\n",
        "    data = normalized.reshape(-1, n_timesteps, n_features)\n",
        "    return data, scaler\n",
        "\n",
        "def conditional_pad_multivariate(X):\n",
        "    num_timesteps = X.shape[1]\n",
        "\n",
        "    if num_timesteps % 4 != 0:\n",
        "        next_num = (int(num_timesteps / 4) + 1) * 4\n",
        "        padding_size = next_num - num_timesteps\n",
        "        X_padded = np.pad(\n",
        "            X, pad_width=((0, 0), (0, padding_size), (0, 0))\n",
        "        )\n",
        "\n",
        "        return X_padded, padding_size\n",
        "\n",
        "    return X, 0\n",
        "\n"
      ],
      "metadata": {
        "id": "MQmQpShMijLz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACTUALL CODE**\n",
        "datasets available : 'Heartbeat', 'SelfRegulationSCP1'"
      ],
      "metadata": {
        "id": "6vVfmpyuZyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y,data_information = load_dataset('PenDigits')\n",
        "print(f'shape of X = {X.shape}')\n",
        "print(f'shape of y = {y.shape}')\n",
        "print(f'data imformation = {data_information}')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "print(f'shape of X train = {X_train.shape}')\n",
        "print(f'shape of y train = {y_train.shape}')"
      ],
      "metadata": {
        "id": "W4m9pwqyVY1b",
        "outputId": "25dde96a-b732-4634-fdd0-f64bd7cfb8fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X = (10992, 2, 8)\n",
            "shape of y = (10992,)\n",
            "data imformation = {'problemname': 'pendigits', 'timestamps': False, 'missing': False, 'univariate': False, 'equallength': True, 'classlabel': True, 'targetlabel': False, 'class_values': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']}\n",
            "shape of X train = (8793, 2, 8)\n",
            "shape of y train = (8793,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "hboRgnd-PPjc",
        "outputId": "7e4d0d96-f7d2-42bd-d25d-076a6589793f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[914 914 915 844 915 844 845 914 844 844]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsample the minority class\n",
        "\n",
        "X_train,y_train = upsample_minority_multivariate(X_train,y_train)\n",
        "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "Q2v7QdrHieA8",
        "outputId": "20ae9c59-ffea-4604-9d7c-a593b66ec5ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[915 915 915 915 915 915 915 915 915 915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.transpose (0,2,1)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "0MgChRpBPuC7",
        "outputId": "a1ead1d2-f6ba-46d7-c946-174d7a63b252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9150, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_training,n_timesteps, n_features= X_train.shape\n",
        "\n",
        "X_train_processed, trained_scaler =  normalize_multivariate(data=X_train, n_timesteps=n_timesteps, n_features = n_features)\n",
        "X_test_processed, _ =  normalize_multivariate(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler, n_features = n_features)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad_multivariate(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad_multivariate(X_test_processed)\n",
        "\n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n",
        "\n",
        "#check the processing (0,1) min should be min 0 and max should be max 1\n",
        "print(f\"\\nmin value = {np.min(X_train)}, max value = {np.max(X_train)}\")\n",
        "print(f\"min value normalized = {np.min(X_train_processed)}, max value normalized= {np.max(X_train_processed)}\")\n",
        "\n",
        "#check that padding paddes the right dimention\n",
        "print(f\"\\nX_train.shape = {X_train.shape}\" )\n",
        "print(f\"X_train_processed_padded.shape = {X_train_processed_padded.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "00Q9QjKy7wEZ",
        "outputId": "2217772e-7b1f-4449-dcf4-45ce8f8fc977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=8, padded #timesteps=8.\n",
            "\n",
            "min value = 0.0, max value = 100.0\n",
            "min value normalized = 0.0, max value normalized= 1.0\n",
            "\n",
            "X_train.shape = (9150, 8, 2)\n",
            "X_train_processed_padded.shape = (9150, 8, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed_padded.shape"
      ],
      "metadata": {
        "id": "xtB-l1KzuUqi",
        "outputId": "3c37ae9c-d175-4273-fbec-d6bf354d0ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9150, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "t1vIzFb8udGj",
        "outputId": "627ec29b-da87-4c14-e8da-d52dfc4baee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9150,)"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "print(f'y = {y_train[idx]}')\n",
        "x_coords = X_train[idx, 0]\n",
        "y_coords = X_train[idx,1]\n",
        "plt.figure(figsize=(5, 5))  # Adjust the figure size as needed\n",
        "plt.plot(x_coords, y_coords, marker='o', linestyle='-')\n",
        "plt.title(\"Handwritten Digit 3\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W6wf7x_ThAWR",
        "outputId": "ee39a47f-b833-4ea1-d171-95387674ca10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_zeroes = y_train[y_train == '0']\n",
        "X_train_zeroes = X_train_processed_padded[y_train == '0' ]\n",
        "y_train_eights = y_train [y_train == '8']\n",
        "X_train_eights = X_train_processed_padded [y_train =='8']\n",
        "y_train = np.concatenate([y_train_zeroes, y_train_eights])\n",
        "X_train = np.concatenate([X_train_zeroes, X_train_eights])\n",
        "y_test_zeroes = y_test[y_test == '0']\n",
        "X_test_zeroes = X_test_processed_padded[y_test == '0' ]\n",
        "y_test_eights = y_test [y_test == '8']\n",
        "X_test_eights = X_test_processed_padded [y_test =='8']\n",
        "y_test = np.concatenate([y_test_zeroes, y_test_eights])\n",
        "X_test = np.concatenate([X_test_zeroes, X_test_eights])\n",
        "X_train, y_train = shuffle(X_train, y_train,random_state=RANDOM_STATE)\n",
        "X_test,y_test = shuffle(X_test,y_test,random_state = RANDOM_STATE)"
      ],
      "metadata": {
        "id": "lqeINlWUnAz7"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(y_train.shape[0]):\n",
        "  if y_train[i] == '8':\n",
        "    y_train[i]=1\n",
        "  else:\n",
        "    y_train [i]=0\n",
        "for i in range(y_test.shape[0]):\n",
        "  if y_test[i] == '8':\n",
        "    y_test[i]=1\n",
        "  else:\n",
        "    y_test[i]=0\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ],
      "metadata": {
        "id": "-Nvkyd-jngzl"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_classes"
      ],
      "metadata": {
        "id": "D2H4Jfux4uHa",
        "outputId": "eca81620-05b2-4fae-9e32-ebdc58591348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "-3ZtKiOmZT1M",
        "outputId": "ebdbc9ab-20b0-4247-832c-349940671e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1830, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "def Classifier(\n",
        "    n_timesteps, n_features, n_conv_layers=1, add_dense_layer=True, n_output=2\n",
        "):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "\n",
        "    input_shape = (n_timesteps, n_features)\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "\n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128)(inputs)\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    if n_output >= 2:\n",
        "        outputs = keras.layers.Dense(n_output, activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return classifier\n",
        "def LSTMFCNClassifier(n_timesteps, n_features, n_output, n_LSTM_cells=8, regularization_rate = 0.001,input_format_stf=True):\n",
        "    # https://github.com/titu1994/LSTM-FCN/blob/master/hyperparameter_search.py\n",
        "    if input_format_stf:\n",
        "      input_shape = (n_timesteps, n_features)\n",
        "    else:\n",
        "      input_shape = (n_features, n_timesteps)\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "    x = keras.layers.LSTM(units=n_LSTM_cells, kernel_regularizer=l2(regularization_rate))(inputs)\n",
        "    x = keras.layers.Dropout(rate=0.6)(x)\n",
        "\n",
        "    y = keras.layers.Permute((2, 1))(inputs)\n",
        "    y = keras.layers.Conv1D(64, 3, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(regularization_rate))(y)\n",
        "    y = keras.layers.BatchNormalization()(y)\n",
        "    y = keras.layers.ReLU()(y)\n",
        "\n",
        "    y = keras.layers.Conv1D(128, 2, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(regularization_rate))(y)\n",
        "    y = keras.layers.BatchNormalization()(y)\n",
        "    y = keras.layers.ReLU()(y)\n",
        "\n",
        "    y = keras.layers.Conv1D(64, 2, padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(regularization_rate))(y)\n",
        "    y = keras.layers.BatchNormalization()(y)\n",
        "    y = keras.layers.ReLU()(y)\n",
        "\n",
        "    y = keras.layers.GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = keras.layers.concatenate([x, y])\n",
        "\n",
        "    outputs = keras.layers.Dense(n_output, activation=\"softmax\", kernel_regularizer=l2(regularization_rate))(x)\n",
        "\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return classifier\n",
        "\n",
        "def ClassifierLSTM(n_timesteps, n_features, extra_lstm_layer=True, n_output=1, input_format_stf = True):\n",
        "    # Define the model structure - only LSTM layers\n",
        "    # https://www.kaggle.com/szaitseff/classification-of-time-series-with-lstm-rnn\n",
        "\n",
        "    if input_format_stf:\n",
        "      input_shape = (n_timesteps, n_features)\n",
        "    else:\n",
        "      input_shape = (n_features, n_timesteps)\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "    if extra_lstm_layer:\n",
        "        x = keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True)(\n",
        "            inputs\n",
        "        )  # set return_sequences true to feed next LSTM layer\n",
        "    else:\n",
        "        x = keras.layers.LSTM(32, activation=\"tanh\", return_sequences=False)(\n",
        "            inputs\n",
        "        )  # set return_sequences false to feed dense layer directly\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    # x = keras.layers.LSTM(32, activation='tanh', return_sequences=True)(x)\n",
        "    # x = keras.layers.BatchNormalization()(x)\n",
        "    if extra_lstm_layer:\n",
        "        x = keras.layers.LSTM(16, activation=\"tanh\", return_sequences=False)(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    if n_output >= 2:\n",
        "        outputs = keras.layers.Dense(n_output, activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    classifier2 = keras.Model(inputs, outputs)\n",
        "\n",
        "    return classifier2\n",
        "\n",
        "def Classifier_FCN(input_shape, nb_classes):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=8, padding=\"same\")(input_layer)\n",
        "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "    conv1 = keras.layers.Activation(activation=\"relu\")(conv1)\n",
        "\n",
        "    conv2 = keras.layers.Conv1D(filters=256, kernel_size=5, padding=\"same\")(conv1)\n",
        "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "    conv2 = keras.layers.Activation(\"relu\")(conv2)\n",
        "\n",
        "    conv3 = keras.layers.Conv1D(128, kernel_size=3, padding=\"same\")(conv2)\n",
        "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "    conv3 = keras.layers.Activation(\"relu\")(conv3)\n",
        "\n",
        "    gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
        "\n",
        "    output_layer = keras.layers.Dense(nb_classes, activation=\"softmax\")(gap_layer)\n",
        "\n",
        "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def EnhancedClassifier(\n",
        "    n_timesteps,\n",
        "    n_features,\n",
        "    n_conv_layers=2,\n",
        "    add_dense_layer=True,\n",
        "    n_output=1,\n",
        "    input_format_stf=True # if True, input is (series, features, timesteps); otherwise (series, timesteps, features)\n",
        "):\n",
        "    # Choose input shape based on the flag\n",
        "    if input_format_stf:\n",
        "      input_shape = (n_features, n_timesteps)\n",
        "    else:\n",
        "      input_shape = (n_timesteps, n_features)\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape, dtype=\"float32\")\n",
        "\n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.TimeDistributed(keras.layers.Dense(128))(x)\n",
        "\n",
        "    for _ in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation='relu')(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\")(x) # Additional dense layer for complexity\n",
        "\n",
        "    if n_output >= 2:\n",
        "        outputs = keras.layers.Dense(n_output, activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return classifier"
      ],
      "metadata": {
        "id": "sD3qinpSEkWK"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed_padded = X_train_processed_padded.transpose(0,2,1)\n",
        "X_test_processed_padded = X_test_processed_padded.transpose(0,2,1)"
      ],
      "metadata": {
        "id": "2tscqoRNiBo-"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "IyhdJrc7iDDH",
        "outputId": "20c8c543-5c4e-40f1-8bee-639d4c8fa519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1830, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "Fp8er70PiEUs",
        "outputId": "9f8c9307-59f0-4645-9781-f2e76e6cb40d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(440, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "JjB5gJx-av2I",
        "outputId": "1cd784fb-1824-4d13-89f2-9507b9c33265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_FORMAT_STF = True\n",
        "if INPUT_FORMAT_STF == False:\n",
        "  X_train = X_train.transpose(0,2,1)\n",
        "  X_test= X_test.transpose(0,2,1)\n",
        "\n",
        "n_lstmcells = 60\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "LSTMFCNclassifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells,input_format_stf=INPUT_FORMAT_STF\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "LSTMFCNclassifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=60, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = LSTMFCNclassifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = LSTMFCNclassifier.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:8\", \"True:0\"],\n",
        "    columns=[\"Pred:8\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "if INPUT_FORMAT_STF == False:\n",
        "  X_train = X_train.transpose(0,2,1)\n",
        "  X_test = X_test.transpose(0,2,1)"
      ],
      "metadata": {
        "id": "yNkKTXe6IIyF",
        "outputId": "87f2cfec-8cc6-4fbb-fe2c-f4c8a93cd186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "153/153 [==============================] - 8s 20ms/step - loss: 0.5776 - accuracy: 0.9754 - val_loss: 1.5016 - val_accuracy: 0.4364\n",
            "Epoch 2/150\n",
            "153/153 [==============================] - 3s 17ms/step - loss: 0.3285 - accuracy: 0.9945 - val_loss: 2.3229 - val_accuracy: 0.4568\n",
            "Epoch 3/150\n",
            "153/153 [==============================] - 3s 18ms/step - loss: 0.2303 - accuracy: 0.9978 - val_loss: 2.2933 - val_accuracy: 0.4455\n",
            "Epoch 4/150\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 0.2014 - accuracy: 0.9902 - val_loss: 2.3293 - val_accuracy: 0.4182\n",
            "Epoch 5/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.1556 - accuracy: 0.9984 - val_loss: 1.7246 - val_accuracy: 0.3023\n",
            "Epoch 6/150\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 0.1313 - accuracy: 0.9984 - val_loss: 2.3640 - val_accuracy: 0.3614\n",
            "Epoch 7/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.1127 - accuracy: 0.9984 - val_loss: 1.9490 - val_accuracy: 0.4568\n",
            "Epoch 8/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.1137 - accuracy: 0.9940 - val_loss: 2.9562 - val_accuracy: 0.3659\n",
            "Epoch 9/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.1023 - accuracy: 0.9978 - val_loss: 2.5072 - val_accuracy: 0.4182\n",
            "Epoch 10/150\n",
            "153/153 [==============================] - 2s 13ms/step - loss: 0.0848 - accuracy: 0.9995 - val_loss: 2.0375 - val_accuracy: 0.4250\n",
            "Epoch 11/150\n",
            "153/153 [==============================] - 3s 16ms/step - loss: 0.0830 - accuracy: 0.9973 - val_loss: 2.2293 - val_accuracy: 0.3364\n",
            "Epoch 12/150\n",
            "153/153 [==============================] - 3s 18ms/step - loss: 0.0744 - accuracy: 0.9989 - val_loss: 1.8678 - val_accuracy: 0.3909\n",
            "Epoch 13/150\n",
            "153/153 [==============================] - 3s 17ms/step - loss: 0.0764 - accuracy: 0.9951 - val_loss: 1.5742 - val_accuracy: 0.4841\n",
            "Epoch 14/150\n",
            "153/153 [==============================] - 2s 14ms/step - loss: 0.0741 - accuracy: 0.9978 - val_loss: 1.4430 - val_accuracy: 0.4114\n",
            "Epoch 15/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0657 - accuracy: 0.9978 - val_loss: 1.6226 - val_accuracy: 0.4318\n",
            "Epoch 16/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.4409\n",
            "Epoch 17/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0516 - accuracy: 0.9995 - val_loss: 1.9355 - val_accuracy: 0.4341\n",
            "Epoch 18/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0525 - accuracy: 0.9995 - val_loss: 2.2669 - val_accuracy: 0.3818\n",
            "Epoch 19/150\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 0.0616 - accuracy: 0.9945 - val_loss: 2.2097 - val_accuracy: 0.4886\n",
            "Epoch 20/150\n",
            "153/153 [==============================] - 2s 12ms/step - loss: 0.0548 - accuracy: 0.9989 - val_loss: 2.0640 - val_accuracy: 0.4955\n",
            "Epoch 21/150\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 0.0461 - accuracy: 0.9995 - val_loss: 1.8980 - val_accuracy: 0.5000\n",
            "Epoch 22/150\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 0.0590 - accuracy: 0.9945 - val_loss: 2.9970 - val_accuracy: 0.4795\n",
            "Epoch 23/150\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 0.0533 - accuracy: 0.9989 - val_loss: 2.2009 - val_accuracy: 0.4773\n",
            "Epoch 24/150\n",
            "153/153 [==============================] - 2s 13ms/step - loss: 0.0476 - accuracy: 0.9989 - val_loss: 2.1789 - val_accuracy: 0.4591\n",
            "Epoch 25/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 2.2269 - val_accuracy: 0.4545\n",
            "Epoch 26/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 0.4523\n",
            "Epoch 27/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0373 - accuracy: 0.9989 - val_loss: 3.4290 - val_accuracy: 0.4000\n",
            "Epoch 28/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0345 - accuracy: 0.9989 - val_loss: 2.4716 - val_accuracy: 0.3659\n",
            "Epoch 29/150\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 2.1426 - val_accuracy: 0.3727\n",
            "Epoch 30/150\n",
            "153/153 [==============================] - 2s 14ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 2.1135 - val_accuracy: 0.4000\n",
            "Epoch 31/150\n",
            " 61/153 [==========>...................] - ETA: 1s - loss: 0.0268 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-363-a63d820504b9>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mreset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training log for LSTM-FCN classifier:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m classifier_history = LSTMFCNclassifier.fit(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "6k2-PO1ofJ3t",
        "outputId": "e6c7cfa9-850a-4d0c-b1d3-718e9d2e6a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ## 2.0 classifier\n",
        "###############################################\n",
        "# ###  classifier\n",
        "input_shape = (n_timesteps_padded, n_features)\n",
        "classifier = Classifier_FCN(\n",
        "    input_shape, 2\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:8\", \"True:0\"],\n",
        "    columns=[\"Pred:8\", \"Pred:0\"],\n",
        ")\n",
        "print(confusion_matrix_df)\n"
      ],
      "metadata": {
        "id": "fOTdEZgLNmJr",
        "outputId": "d3aa1f30-5e6e-4c21-8812-79cc7a91de39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM-FCN classifier:\n",
            "Epoch 1/150\n",
            "58/58 [==============================] - 7s 14ms/step - loss: 0.0662 - accuracy: 0.9842 - val_loss: 0.7070 - val_accuracy: 0.4795\n",
            "Epoch 2/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9989 - val_loss: 0.7291 - val_accuracy: 0.4659\n",
            "Epoch 3/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.9681 - val_accuracy: 0.4795\n",
            "Epoch 4/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.9059 - val_accuracy: 0.4614\n",
            "Epoch 5/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 1.2405 - val_accuracy: 0.4568\n",
            "Epoch 6/150\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 1.1427 - val_accuracy: 0.3205\n",
            "Epoch 7/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.3164 - val_accuracy: 0.2977\n",
            "Epoch 8/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5495 - val_accuracy: 0.3386\n",
            "Epoch 9/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7628 - val_accuracy: 0.3477\n",
            "Epoch 10/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0506 - val_accuracy: 0.3864\n",
            "Epoch 11/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5585 - val_accuracy: 0.4477\n",
            "Epoch 12/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 9.2234e-04 - accuracy: 1.0000 - val_loss: 2.4098 - val_accuracy: 0.4023\n",
            "Epoch 13/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 7.8513e-04 - accuracy: 1.0000 - val_loss: 2.4905 - val_accuracy: 0.4045\n",
            "Epoch 14/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 7.2724e-04 - accuracy: 1.0000 - val_loss: 2.3885 - val_accuracy: 0.3818\n",
            "Epoch 15/150\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 4.0283e-04 - accuracy: 1.0000 - val_loss: 2.4496 - val_accuracy: 0.3705\n",
            "Epoch 16/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.6241e-04 - accuracy: 1.0000 - val_loss: 2.4728 - val_accuracy: 0.3659\n",
            "Epoch 17/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.9734e-04 - accuracy: 1.0000 - val_loss: 2.6000 - val_accuracy: 0.3682\n",
            "Epoch 18/150\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 3.2237e-04 - accuracy: 1.0000 - val_loss: 2.6924 - val_accuracy: 0.3841\n",
            "Epoch 19/150\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 2.8393e-04 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.3705\n",
            "Epoch 20/150\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 3.2573e-04 - accuracy: 1.0000 - val_loss: 2.7531 - val_accuracy: 0.3841\n",
            "Epoch 21/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.0146e-04 - accuracy: 1.0000 - val_loss: 2.8146 - val_accuracy: 0.3977\n",
            "Epoch 22/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.3319 - val_accuracy: 0.3932\n",
            "Epoch 23/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 6.7611e-04 - accuracy: 1.0000 - val_loss: 3.2787 - val_accuracy: 0.4068\n",
            "Epoch 24/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.3948e-04 - accuracy: 1.0000 - val_loss: 2.7210 - val_accuracy: 0.3614\n",
            "Epoch 25/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 1.6291e-04 - accuracy: 1.0000 - val_loss: 2.7426 - val_accuracy: 0.3545\n",
            "Epoch 26/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.3309e-04 - accuracy: 1.0000 - val_loss: 2.7412 - val_accuracy: 0.3386\n",
            "Epoch 27/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 7.5260e-04 - accuracy: 1.0000 - val_loss: 2.1582 - val_accuracy: 0.5136\n",
            "Epoch 28/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.0922e-04 - accuracy: 1.0000 - val_loss: 2.2591 - val_accuracy: 0.3477\n",
            "Epoch 29/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 1.6315e-04 - accuracy: 1.0000 - val_loss: 2.7219 - val_accuracy: 0.3773\n",
            "Epoch 30/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 2.1809e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.3909\n",
            "Epoch 31/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 2.0022 - val_accuracy: 0.4318\n",
            "Epoch 32/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 3.4136 - val_accuracy: 0.4614\n",
            "Epoch 33/150\n",
            "58/58 [==============================] - 1s 8ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 4.2786 - val_accuracy: 0.4864\n",
            "Epoch 34/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 5.6719 - val_accuracy: 0.4795\n",
            "Epoch 35/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3274 - val_accuracy: 0.4432\n",
            "Epoch 36/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 4.3027e-04 - accuracy: 1.0000 - val_loss: 2.7265 - val_accuracy: 0.4364\n",
            "Epoch 37/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.2088e-04 - accuracy: 1.0000 - val_loss: 2.2947 - val_accuracy: 0.3818\n",
            "Epoch 38/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 9.7178e-05 - accuracy: 1.0000 - val_loss: 2.4672 - val_accuracy: 0.3977\n",
            "Epoch 39/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1158e-04 - accuracy: 1.0000 - val_loss: 2.5887 - val_accuracy: 0.4045\n",
            "Epoch 40/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 7.6307e-05 - accuracy: 1.0000 - val_loss: 3.0026 - val_accuracy: 0.4318\n",
            "Epoch 41/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 7.6233e-05 - accuracy: 1.0000 - val_loss: 2.9161 - val_accuracy: 0.4273\n",
            "Epoch 42/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 6.0976e-05 - accuracy: 1.0000 - val_loss: 2.9065 - val_accuracy: 0.4273\n",
            "Epoch 43/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4630e-04 - accuracy: 1.0000 - val_loss: 3.0723 - val_accuracy: 0.4295\n",
            "Epoch 44/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 8.6111e-05 - accuracy: 1.0000 - val_loss: 2.9760 - val_accuracy: 0.4227\n",
            "Epoch 45/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 1.9232 - val_accuracy: 0.3227\n",
            "Epoch 46/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 3.0565 - val_accuracy: 0.3091\n",
            "Epoch 47/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 2.5300 - val_accuracy: 0.3114\n",
            "Epoch 48/150\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2723 - val_accuracy: 0.4545\n",
            "Epoch 49/150\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 5.4700e-04 - accuracy: 1.0000 - val_loss: 3.1249 - val_accuracy: 0.4636\n",
            "Epoch 50/150\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 3.4832e-04 - accuracy: 1.0000 - val_loss: 3.2633 - val_accuracy: 0.4636\n",
            "Epoch 51/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 2.0736e-04 - accuracy: 1.0000 - val_loss: 3.3752 - val_accuracy: 0.4682\n",
            "Epoch 52/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 3.4445e-04 - accuracy: 1.0000 - val_loss: 3.2902 - val_accuracy: 0.4545\n",
            "Epoch 53/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.2306e-04 - accuracy: 1.0000 - val_loss: 3.4938 - val_accuracy: 0.4659\n",
            "Epoch 54/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.5410e-04 - accuracy: 1.0000 - val_loss: 3.6451 - val_accuracy: 0.4682\n",
            "Epoch 55/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.0938e-04 - accuracy: 1.0000 - val_loss: 3.6689 - val_accuracy: 0.4682\n",
            "Epoch 56/150\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 2.1266e-04 - accuracy: 1.0000 - val_loss: 3.6683 - val_accuracy: 0.4682\n",
            "Epoch 57/150\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 2.0398e-04 - accuracy: 1.0000 - val_loss: 3.7489 - val_accuracy: 0.4614\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.5046255096338914.\n",
            "        Pred:8  Pred:0\n",
            "True:8      60     151\n",
            "True:0      63     166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "INPUT_FORMAT_STF = True\n",
        "\n",
        "reset_seeds()\n",
        "###############################################\n",
        "# ### LSTM classifier\n",
        "if INPUT_FORMAT_STF == False:\n",
        "    X_train = X_train.transpose(0,2,1)\n",
        "    X_test = X_test.transpose(0,2,1)\n",
        "\n",
        "classifierLSTM = ClassifierLSTM(n_timesteps_padded, n_features,extra_lstm_layer=True, n_output=2, input_format_stf=INPUT_FORMAT_STF)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "classifierLSTM.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for LSTM classifier:\")\n",
        "classifier_history = classifierLSTM.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=42,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifierLSTM.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")\n",
        "if INPUT_FORMAT_STF == False:\n",
        "  X_train= X_train.transpose(0,2,1)\n",
        "  X_test= X_test.transpose(0,2,1)"
      ],
      "metadata": {
        "id": "fvEe9-iRwX-h",
        "outputId": "e7e16382-44e1-4b38-8c10-05f85d33988e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for LSTM classifier:\n",
            "Epoch 1/150\n",
            "44/44 - 6s - loss: 0.2745 - accuracy: 0.9290 - val_loss: 0.7083 - val_accuracy: 0.3841 - 6s/epoch - 143ms/step\n",
            "Epoch 2/150\n",
            "44/44 - 0s - loss: 0.1379 - accuracy: 0.9743 - val_loss: 0.7244 - val_accuracy: 0.4682 - 362ms/epoch - 8ms/step\n",
            "Epoch 3/150\n",
            "44/44 - 0s - loss: 0.0887 - accuracy: 0.9863 - val_loss: 0.7458 - val_accuracy: 0.4273 - 376ms/epoch - 9ms/step\n",
            "Epoch 4/150\n",
            "44/44 - 0s - loss: 0.0633 - accuracy: 0.9891 - val_loss: 0.7796 - val_accuracy: 0.3841 - 365ms/epoch - 8ms/step\n",
            "Epoch 5/150\n",
            "44/44 - 0s - loss: 0.0433 - accuracy: 0.9929 - val_loss: 0.8282 - val_accuracy: 0.3750 - 462ms/epoch - 11ms/step\n",
            "Epoch 6/150\n",
            "44/44 - 0s - loss: 0.0356 - accuracy: 0.9978 - val_loss: 0.9110 - val_accuracy: 0.3295 - 487ms/epoch - 11ms/step\n",
            "Epoch 7/150\n",
            "44/44 - 0s - loss: 0.0241 - accuracy: 0.9984 - val_loss: 1.0582 - val_accuracy: 0.3364 - 471ms/epoch - 11ms/step\n",
            "Epoch 8/150\n",
            "44/44 - 0s - loss: 0.0247 - accuracy: 0.9962 - val_loss: 1.1530 - val_accuracy: 0.2568 - 496ms/epoch - 11ms/step\n",
            "Epoch 9/150\n",
            "44/44 - 0s - loss: 0.0184 - accuracy: 0.9984 - val_loss: 1.4024 - val_accuracy: 0.3023 - 493ms/epoch - 11ms/step\n",
            "Epoch 10/150\n",
            "44/44 - 1s - loss: 0.0123 - accuracy: 0.9989 - val_loss: 1.7292 - val_accuracy: 0.3227 - 540ms/epoch - 12ms/step\n",
            "Epoch 11/150\n",
            "44/44 - 1s - loss: 0.0118 - accuracy: 0.9984 - val_loss: 1.9245 - val_accuracy: 0.3386 - 514ms/epoch - 12ms/step\n",
            "Epoch 12/150\n",
            "44/44 - 1s - loss: 0.0117 - accuracy: 0.9989 - val_loss: 2.0505 - val_accuracy: 0.2818 - 536ms/epoch - 12ms/step\n",
            "Epoch 13/150\n",
            "44/44 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.3938 - val_accuracy: 0.2909 - 511ms/epoch - 12ms/step\n",
            "Epoch 14/150\n",
            "44/44 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.4506 - val_accuracy: 0.2523 - 577ms/epoch - 13ms/step\n",
            "Epoch 15/150\n",
            "44/44 - 0s - loss: 0.0076 - accuracy: 0.9989 - val_loss: 2.3721 - val_accuracy: 0.2318 - 496ms/epoch - 11ms/step\n",
            "Epoch 16/150\n",
            "44/44 - 1s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 2.5496 - val_accuracy: 0.2386 - 515ms/epoch - 12ms/step\n",
            "Epoch 17/150\n",
            "44/44 - 1s - loss: 0.0058 - accuracy: 0.9995 - val_loss: 2.5887 - val_accuracy: 0.2795 - 518ms/epoch - 12ms/step\n",
            "Epoch 18/150\n",
            "44/44 - 1s - loss: 0.0046 - accuracy: 0.9995 - val_loss: 2.5570 - val_accuracy: 0.2909 - 508ms/epoch - 12ms/step\n",
            "Epoch 19/150\n",
            "44/44 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6737 - val_accuracy: 0.2568 - 521ms/epoch - 12ms/step\n",
            "Epoch 20/150\n",
            "44/44 - 1s - loss: 0.0051 - accuracy: 0.9989 - val_loss: 2.6190 - val_accuracy: 0.2977 - 535ms/epoch - 12ms/step\n",
            "Epoch 21/150\n",
            "44/44 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8451 - val_accuracy: 0.2818 - 487ms/epoch - 11ms/step\n",
            "Epoch 22/150\n",
            "44/44 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9765 - val_accuracy: 0.2841 - 358ms/epoch - 8ms/step\n",
            "Epoch 23/150\n",
            "44/44 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8933 - val_accuracy: 0.2682 - 357ms/epoch - 8ms/step\n",
            "Epoch 24/150\n",
            "44/44 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9033 - val_accuracy: 0.2614 - 383ms/epoch - 9ms/step\n",
            "Epoch 25/150\n",
            "44/44 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9720 - val_accuracy: 0.2773 - 381ms/epoch - 9ms/step\n",
            "Epoch 26/150\n",
            "44/44 - 0s - loss: 0.0032 - accuracy: 0.9989 - val_loss: 2.8298 - val_accuracy: 0.2955 - 358ms/epoch - 8ms/step\n",
            "Epoch 27/150\n",
            "44/44 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0480 - val_accuracy: 0.2841 - 337ms/epoch - 8ms/step\n",
            "Epoch 28/150\n",
            "44/44 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0569 - val_accuracy: 0.2727 - 366ms/epoch - 8ms/step\n",
            "Epoch 29/150\n",
            "44/44 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0695 - val_accuracy: 0.2932 - 357ms/epoch - 8ms/step\n",
            "Epoch 30/150\n",
            "44/44 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0412 - val_accuracy: 0.2818 - 401ms/epoch - 9ms/step\n",
            "Epoch 31/150\n",
            "44/44 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0621 - val_accuracy: 0.3727 - 425ms/epoch - 10ms/step\n",
            "Epoch 32/150\n",
            "44/44 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1081 - val_accuracy: 0.2864 - 391ms/epoch - 9ms/step\n",
            "14/14 [==============================] - 1s 3ms/step\n",
            "LSTM classifier trained, with validation accuracy 0.48796539663486416.\n",
            "Confusion matrix: \n",
            "          Pred:pos  Pred:neg\n",
            "True:pos       205         6\n",
            "True:neg       228         1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Autoencoder(n_timesteps, n_features):\n",
        "    # Define encoder and decoder structure\n",
        "    def Encoder(input):\n",
        "        x = keras.layers.Conv1D(\n",
        "            filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "        )(input)\n",
        "        x = keras.layers.MaxPool1D(pool_size=2, padding=\"same\")(x)\n",
        "        x = keras.layers.Conv1D(\n",
        "            filters=32, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "        )(x)\n",
        "        x = keras.layers.MaxPool1D(pool_size=2, padding=\"same\")(x)\n",
        "        return x\n",
        "\n",
        "    def Decoder(input):\n",
        "        x = keras.layers.Conv1D(\n",
        "            filters=32, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "        )(input)\n",
        "        x = keras.layers.UpSampling1D(size=2)(x)\n",
        "        x = keras.layers.Conv1D(\n",
        "            filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "        )(x)\n",
        "        # x = keras.layers.Conv1D(filters=64, kernel_size=2, activation=\"relu\")(x)\n",
        "        x = keras.layers.UpSampling1D(size=2)(x)\n",
        "        x = keras.layers.Conv1D(\n",
        "            filters=1, kernel_size=3, activation=\"linear\", padding=\"same\"\n",
        "        )(x)\n",
        "        return x\n",
        "\n",
        "    # Define the AE model\n",
        "    orig_input = keras.Input(shape=(n_timesteps,n_features))\n",
        "    autoencoder = keras.Model(inputs=orig_input, outputs=Decoder(Encoder(orig_input)))\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "def AutoencoderLSTM(n_timesteps, n_features):\n",
        "    # Define encoder and decoder structure\n",
        "    # structure from medium post: https://towardsdatascience.com/step-by-step-understanding-lstm-autoencoder-layers-ffab055b6352\n",
        "    def EncoderLSTM(input):\n",
        "        # x = keras.layers.LSTM(64, activation='relu', return_sequences=True)(input)\n",
        "        x = keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True)(input)\n",
        "        # encoded = keras.layers.LSTM(32, activation='relu', return_sequences=False)(x)\n",
        "        encoded = keras.layers.LSTM(32, activation=\"tanh\", return_sequences=False)(x)\n",
        "        return encoded\n",
        "\n",
        "    def DecoderLSTM(encoded):\n",
        "        x = keras.layers.RepeatVector(n_timesteps)(encoded)\n",
        "        # x = keras.layers.LSTM(32, activation='relu', return_sequences=True)(x)\n",
        "        x = keras.layers.LSTM(32, activation=\"tanh\", return_sequences=True)(x)\n",
        "        # x = keras.layers.LSTM(64, activation='relu', return_sequences=True)(x)\n",
        "        x = keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True)(x)\n",
        "        decoded = keras.layers.TimeDistributed(\n",
        "            keras.layers.Dense(n_features, activation=\"sigmoid\")\n",
        "        )(x)\n",
        "        return decoded\n",
        "\n",
        "    # Define the AE model\n",
        "    orig_input2 = keras.Input(shape=( n_timesteps,n_features))\n",
        "\n",
        "    autoencoder2 = keras.Model(\n",
        "        inputs=orig_input2, outputs=DecoderLSTM(EncoderLSTM(orig_input2))\n",
        "    )\n",
        "\n",
        "    return autoencoder2\n",
        "\n"
      ],
      "metadata": {
        "id": "YopwiyfxDr_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed_padded.shape"
      ],
      "metadata": {
        "id": "0kU7VTl9Ev-I",
        "outputId": "0ed081ce-557f-4178-e042-f58b8bdc815f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450, 896, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features )\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ],
      "metadata": {
        "id": "E6IxH8BLEKFG",
        "outputId": "3b0127af-2f36-4328-92b5-6b3ad3abc9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "15/15 - 6s - loss: 0.0616 - val_loss: 0.0144 - 6s/epoch - 377ms/step\n",
            "Epoch 2/50\n",
            "15/15 - 0s - loss: 0.0046 - val_loss: 0.0013 - 394ms/epoch - 26ms/step\n",
            "Epoch 3/50\n",
            "15/15 - 0s - loss: 0.0016 - val_loss: 0.0014 - 339ms/epoch - 23ms/step\n",
            "Epoch 4/50\n",
            "15/15 - 0s - loss: 0.0011 - val_loss: 0.0011 - 416ms/epoch - 28ms/step\n",
            "Epoch 5/50\n",
            "15/15 - 0s - loss: 8.5874e-04 - val_loss: 6.6260e-04 - 367ms/epoch - 24ms/step\n",
            "Epoch 6/50\n",
            "15/15 - 0s - loss: 6.2007e-04 - val_loss: 6.1036e-04 - 390ms/epoch - 26ms/step\n",
            "Epoch 7/50\n",
            "15/15 - 0s - loss: 5.8653e-04 - val_loss: 5.9504e-04 - 356ms/epoch - 24ms/step\n",
            "Epoch 8/50\n",
            "15/15 - 0s - loss: 5.7407e-04 - val_loss: 5.8598e-04 - 379ms/epoch - 25ms/step\n",
            "Epoch 9/50\n",
            "15/15 - 0s - loss: 5.6770e-04 - val_loss: 5.8126e-04 - 396ms/epoch - 26ms/step\n",
            "Epoch 10/50\n",
            "15/15 - 0s - loss: 5.6435e-04 - val_loss: 5.7918e-04 - 405ms/epoch - 27ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.0005791778094135225.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoderLSTM = AutoencoderLSTM(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoderLSTM.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "print(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoderLSTM.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")"
      ],
      "metadata": {
        "id": "C5Sk6xWIKxMd",
        "outputId": "403e8d4c-b05b-47a7-9eac-24ec6dd0668e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log for 1dCNN autoencoder:\n",
            "Epoch 1/50\n",
            "15/15 - 14s - loss: 0.0197 - val_loss: 0.0089 - 14s/epoch - 904ms/step\n",
            "Epoch 2/50\n",
            "15/15 - 2s - loss: 0.0110 - val_loss: 0.0086 - 2s/epoch - 138ms/step\n",
            "Epoch 3/50\n",
            "15/15 - 2s - loss: 0.0103 - val_loss: 0.0081 - 2s/epoch - 118ms/step\n",
            "Epoch 4/50\n",
            "15/15 - 2s - loss: 0.0098 - val_loss: 0.0079 - 2s/epoch - 105ms/step\n",
            "Epoch 5/50\n",
            "15/15 - 3s - loss: 0.0080 - val_loss: 0.0044 - 3s/epoch - 197ms/step\n",
            "Epoch 6/50\n",
            "15/15 - 3s - loss: 0.0058 - val_loss: 0.0044 - 3s/epoch - 229ms/step\n",
            "Epoch 7/50\n",
            "15/15 - 3s - loss: 0.0049 - val_loss: 0.0042 - 3s/epoch - 205ms/step\n",
            "Epoch 8/50\n",
            "15/15 - 2s - loss: 0.0043 - val_loss: 0.0040 - 2s/epoch - 105ms/step\n",
            "Epoch 9/50\n",
            "15/15 - 1s - loss: 0.0042 - val_loss: 0.0044 - 1s/epoch - 90ms/step\n",
            "Epoch 10/50\n",
            "15/15 - 1s - loss: 0.0041 - val_loss: 0.0034 - 1s/epoch - 92ms/step\n",
            "Epoch 11/50\n",
            "15/15 - 1s - loss: 0.0043 - val_loss: 0.0033 - 1s/epoch - 91ms/step\n",
            "Epoch 12/50\n",
            "15/15 - 1s - loss: 0.0038 - val_loss: 0.0051 - 1s/epoch - 91ms/step\n",
            "Epoch 13/50\n",
            "15/15 - 1s - loss: 0.0050 - val_loss: 0.0040 - 1s/epoch - 91ms/step\n",
            "Epoch 14/50\n",
            "15/15 - 1s - loss: 0.0040 - val_loss: 0.0036 - 1s/epoch - 90ms/step\n",
            "Epoch 15/50\n",
            "15/15 - 2s - loss: 0.0038 - val_loss: 0.0032 - 2s/epoch - 101ms/step\n",
            "Epoch 16/50\n",
            "15/15 - 2s - loss: 0.0037 - val_loss: 0.0033 - 2s/epoch - 131ms/step\n",
            "Epoch 17/50\n",
            "15/15 - 2s - loss: 0.0040 - val_loss: 0.0036 - 2s/epoch - 133ms/step\n",
            "Epoch 18/50\n",
            "15/15 - 2s - loss: 0.0041 - val_loss: 0.0033 - 2s/epoch - 132ms/step\n",
            "Epoch 19/50\n",
            "15/15 - 2s - loss: 0.0037 - val_loss: 0.0034 - 2s/epoch - 118ms/step\n",
            "Epoch 20/50\n",
            "15/15 - 1s - loss: 0.0038 - val_loss: 0.0038 - 1s/epoch - 92ms/step\n",
            "Epoch 21/50\n",
            "15/15 - 1s - loss: 0.0039 - val_loss: 0.0033 - 1s/epoch - 93ms/step\n",
            "1dCNN autoencoder trained, with validation loss: 0.003235831158235669.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from wildboar.explain import IntervalImportance\n",
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "def get_global_weight_univariate(\n",
        "    input_samples, input_labels, classifier_model, n_timesteps, n_features, random_state=None,\n",
        "):\n",
        "    n_samples, n_timesteps, n_dims = input_samples.shape  # n_dims=1\n",
        "\n",
        "    class ModelWrapper:\n",
        "        def __init__(self, model, n_timesteps, n_features):\n",
        "            self.model = model\n",
        "            self.fitted_ = False\n",
        "            self.n_timesteps_in_ = n_timesteps\n",
        "            self.n_features_in_ = n_features\n",
        "\n",
        "        def predict(self, X):\n",
        "            p = self.model.predict(X.reshape(n_samples, n_timesteps, 1))\n",
        "            return np.argmax(p, axis=1)\n",
        "\n",
        "        def fit(self, X, y):\n",
        "\n",
        "          self.fitted_ = True\n",
        "          return self.model.fit(X, y)\n",
        "\n",
        "    clf = ModelWrapper(classifier_model, n_timesteps, n_features)\n",
        "\n",
        "    i = IntervalImportance(scoring=\"accuracy\",n_intervals=10, random_state=random_state)\n",
        "    i.fit(clf, input_samples.reshape(input_samples.shape[0], -1), input_labels)\n",
        "\n",
        "    # calculate the threshold of masking, 75 percentile\n",
        "    masking_threshold = np.percentile(i.importances_.mean, 75)\n",
        "    masking_idx = np.where(i.importances_.mean >= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    seg_idx = i.components_\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, 1)\n",
        "    return weighted_steps"
      ],
      "metadata": {
        "id": "4kov5Co9s9FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "from help_functions import evaluate2\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weightstr(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        n_timesteps= n_timesteps,\n",
        "        n_features=n_features,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    print(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # get the negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "    y_pred_neg = y_pred_classes[y_pred_classes==neg_label][:10]\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        y_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate2(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )"
      ],
      "metadata": {
        "id": "hysd9dxSsx9h",
        "outputId": "fcd37e48-0a5e-4ab5-e040-954ac9c52108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-ba2a14e1fb40>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"global\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     step_weights = get_global_weightstr(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mX_train_processed_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_train_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-9373664d2beb>\u001b[0m in \u001b[0;36mget_global_weightstr\u001b[0;34m(input_samples, input_labels, classifier_model, n_timesteps, n_features, random_state)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntervalImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# calculate the threshold of masking, 75 percentile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wildboar/explain/_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, estimator, x, y, sample_weight)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wildboar/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_timesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wildboar/base.py\u001b[0m in \u001b[0;36m_check_n_timesteps\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_timesteps\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_timesteps_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"X has {n_timesteps} timesteps, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_timesteps_in_} timesteps as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 5376 timesteps, but IntervalImportance is expecting 896 timesteps as input."
          ]
        }
      ]
    }
  ]
}