{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f239ef",
      "metadata": {
        "id": "a0f239ef"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a307b064",
      "metadata": {
        "id": "a307b064",
        "outputId": "1063d6e8-78f3-401c-a5ce-fcced65ed4a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 211 (delta 56), reused 24 (delta 24), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (211/211), 1.70 MiB | 4.36 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "/content/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        "%cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "98202777",
      "metadata": {
        "id": "98202777"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "cd622a74",
      "metadata": {
        "id": "cd622a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e696b2-8250-4966-a8df-43551f73d515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 KB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.4/981.4 KB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 KB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ad8718d5",
      "metadata": {
        "id": "ad8718d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "772e4dd0",
      "metadata": {
        "id": "772e4dd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "08a756fb",
      "metadata": {
        "id": "08a756fb"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7845e90e",
      "metadata": {
        "id": "7845e90e",
        "outputId": "ca95e56f-2bdc-49ae-dfca-ffdcf3c833be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "%cd src\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ef330b1e",
      "metadata": {
        "id": "ef330b1e"
      },
      "outputs": [],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "80b4f195",
      "metadata": {
        "id": "80b4f195",
        "outputId": "e4fde7a1-a3a8-4fb4-cc2f-f1fd7c4dcfb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "gpu_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a87d6e5f",
      "metadata": {
        "id": "a87d6e5f"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d6ff63c0",
      "metadata": {
        "id": "d6ff63c0"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"FordA\"\n",
        "OUTPUT_FILENAME = \"FordA-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "774a78f4",
      "metadata": {
        "id": "774a78f4"
      },
      "outputs": [],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = -1\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "66181d53",
      "metadata": {
        "id": "66181d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2f6a37-f2b6-49d1-df15-29965da7826f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=500, padded #timesteps=500.\n"
          ]
        }
      ],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_processed.shape)\n",
        "print(X_train_processed_padded.shape)"
      ],
      "metadata": {
        "id": "-_watlod7tQQ",
        "outputId": "ef3d119e-fea4-4b9e-e9e6-6b19c0c57a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-_watlod7tQQ",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4042, 500, 1)\n",
            "(4042, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "03febb4b",
      "metadata": {
        "id": "03febb4b"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e8f551c9",
      "metadata": {
        "scrolled": true,
        "id": "e8f551c9",
        "outputId": "b4ee93a7-1e0e-4b77-e32b-e770b522b964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127/127 [==============================] - 5s 23ms/step - loss: 0.6543 - accuracy: 0.6366 - val_loss: 0.6943 - val_accuracy: 0.5137\n",
            "Epoch 2/150\n",
            "127/127 [==============================] - 2s 17ms/step - loss: 0.5187 - accuracy: 0.7813 - val_loss: 0.6985 - val_accuracy: 0.5137\n",
            "Epoch 3/150\n",
            "127/127 [==============================] - 4s 33ms/step - loss: 0.4450 - accuracy: 0.8243 - val_loss: 0.6613 - val_accuracy: 0.5716\n",
            "Epoch 4/150\n",
            "127/127 [==============================] - 5s 42ms/step - loss: 0.3711 - accuracy: 0.8669 - val_loss: 0.5569 - val_accuracy: 0.7340\n",
            "Epoch 5/150\n",
            "127/127 [==============================] - 4s 33ms/step - loss: 0.3147 - accuracy: 0.8934 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
            "Epoch 6/150\n",
            "127/127 [==============================] - 5s 39ms/step - loss: 0.2595 - accuracy: 0.9196 - val_loss: 0.4860 - val_accuracy: 0.7777\n",
            "Epoch 7/150\n",
            "127/127 [==============================] - 6s 43ms/step - loss: 0.2222 - accuracy: 0.9312 - val_loss: 0.4936 - val_accuracy: 0.7736\n",
            "Epoch 8/150\n",
            "127/127 [==============================] - 5s 36ms/step - loss: 0.1996 - accuracy: 0.9377 - val_loss: 0.4804 - val_accuracy: 0.7888\n",
            "Epoch 9/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.1749 - accuracy: 0.9468 - val_loss: 0.4891 - val_accuracy: 0.7827\n",
            "Epoch 10/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.1565 - accuracy: 0.9510 - val_loss: 0.4813 - val_accuracy: 0.8112\n",
            "Epoch 11/150\n",
            "127/127 [==============================] - 3s 25ms/step - loss: 0.1386 - accuracy: 0.9604 - val_loss: 0.4714 - val_accuracy: 0.8051\n",
            "Epoch 12/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.1165 - accuracy: 0.9673 - val_loss: 0.4872 - val_accuracy: 0.8000\n",
            "Epoch 13/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.1105 - accuracy: 0.9706 - val_loss: 0.4657 - val_accuracy: 0.8030\n",
            "Epoch 14/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0986 - accuracy: 0.9738 - val_loss: 0.5311 - val_accuracy: 0.7959\n",
            "Epoch 15/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0820 - accuracy: 0.9800 - val_loss: 0.5018 - val_accuracy: 0.8030\n",
            "Epoch 16/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0829 - accuracy: 0.9819 - val_loss: 0.5308 - val_accuracy: 0.8010\n",
            "Epoch 17/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0752 - accuracy: 0.9787 - val_loss: 0.5287 - val_accuracy: 0.8030\n",
            "Epoch 18/150\n",
            "127/127 [==============================] - 2s 17ms/step - loss: 0.0687 - accuracy: 0.9849 - val_loss: 0.5540 - val_accuracy: 0.7939\n",
            "Epoch 19/150\n",
            "127/127 [==============================] - 2s 17ms/step - loss: 0.0696 - accuracy: 0.9797 - val_loss: 0.5917 - val_accuracy: 0.7898\n",
            "Epoch 20/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0564 - accuracy: 0.9871 - val_loss: 0.5688 - val_accuracy: 0.8071\n",
            "Epoch 21/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0607 - accuracy: 0.9849 - val_loss: 0.5692 - val_accuracy: 0.8010\n",
            "Epoch 22/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0496 - accuracy: 0.9879 - val_loss: 0.6083 - val_accuracy: 0.7756\n",
            "Epoch 23/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0453 - accuracy: 0.9911 - val_loss: 0.5509 - val_accuracy: 0.8020\n",
            "Epoch 24/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0560 - accuracy: 0.9842 - val_loss: 0.5949 - val_accuracy: 0.7980\n",
            "Epoch 25/150\n",
            "127/127 [==============================] - 2s 17ms/step - loss: 0.0368 - accuracy: 0.9938 - val_loss: 0.5709 - val_accuracy: 0.8051\n",
            "Epoch 26/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0424 - accuracy: 0.9886 - val_loss: 0.5831 - val_accuracy: 0.8142\n",
            "Epoch 27/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 0.6344 - val_accuracy: 0.7807\n",
            "Epoch 28/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0443 - accuracy: 0.9891 - val_loss: 0.6426 - val_accuracy: 0.8041\n",
            "Epoch 29/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.6358 - val_accuracy: 0.7919\n",
            "Epoch 30/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0303 - accuracy: 0.9951 - val_loss: 0.6015 - val_accuracy: 0.8122\n",
            "Epoch 31/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0298 - accuracy: 0.9938 - val_loss: 0.5909 - val_accuracy: 0.8091\n",
            "Epoch 32/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 0.6374 - val_accuracy: 0.7959\n",
            "Epoch 33/150\n",
            "127/127 [==============================] - 3s 25ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 0.6625 - val_accuracy: 0.7970\n",
            "Epoch 34/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.6590 - val_accuracy: 0.7929\n",
            "Epoch 35/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.6695 - val_accuracy: 0.7970\n",
            "Epoch 36/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.6517 - val_accuracy: 0.8051\n",
            "Epoch 37/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.6194 - val_accuracy: 0.8132\n",
            "Epoch 38/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.6469 - val_accuracy: 0.7959\n",
            "Epoch 39/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.6553 - val_accuracy: 0.8112\n",
            "Epoch 40/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.6829 - val_accuracy: 0.8041\n",
            "Epoch 41/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 0.7365 - val_accuracy: 0.7848\n",
            "Epoch 42/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 0.7210 - val_accuracy: 0.7878\n",
            "Epoch 43/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.6584 - val_accuracy: 0.8091\n",
            "Epoch 44/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.6700 - val_accuracy: 0.7980\n",
            "Epoch 45/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.7062 - val_accuracy: 0.7970\n",
            "Epoch 46/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.7162 - val_accuracy: 0.7980\n",
            "Epoch 47/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.7021 - val_accuracy: 0.7990\n",
            "Epoch 48/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 0.6798 - val_accuracy: 0.8030\n",
            "Epoch 49/150\n",
            "127/127 [==============================] - 4s 33ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.7315 - val_accuracy: 0.7939\n",
            "Epoch 50/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.7129 - val_accuracy: 0.8020\n",
            "Epoch 51/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.7277 - val_accuracy: 0.8041\n",
            "Epoch 52/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.6918 - val_accuracy: 0.8041\n",
            "Epoch 53/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.7362 - val_accuracy: 0.8091\n",
            "Epoch 54/150\n",
            "127/127 [==============================] - 3s 26ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.7377 - val_accuracy: 0.8041\n",
            "Epoch 55/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.7521 - val_accuracy: 0.8030\n",
            "Epoch 56/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.7186 - val_accuracy: 0.8162\n",
            "Epoch 57/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.6992 - val_accuracy: 0.8142\n",
            "Epoch 58/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.7299 - val_accuracy: 0.8061\n",
            "Epoch 59/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.7050 - val_accuracy: 0.8122\n",
            "Epoch 60/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.7123 - val_accuracy: 0.8122\n",
            "Epoch 61/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.7308 - val_accuracy: 0.8081\n",
            "Epoch 62/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.7989 - val_accuracy: 0.8000\n",
            "Epoch 63/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.7560 - val_accuracy: 0.7990\n",
            "Epoch 64/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.7599 - val_accuracy: 0.8051\n",
            "Epoch 65/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.7172 - val_accuracy: 0.8081\n",
            "Epoch 66/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.7821 - val_accuracy: 0.8061\n",
            "Epoch 67/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.7526 - val_accuracy: 0.8061\n",
            "Epoch 68/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.7366 - val_accuracy: 0.8213\n",
            "Epoch 69/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.7801 - val_accuracy: 0.8122\n",
            "Epoch 70/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.7381 - val_accuracy: 0.8112\n",
            "Epoch 71/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.8509 - val_accuracy: 0.8000\n",
            "Epoch 72/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.8301 - val_accuracy: 0.8010\n",
            "Epoch 73/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.8314 - val_accuracy: 0.7970\n",
            "Epoch 74/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.7991 - val_accuracy: 0.8041\n",
            "Epoch 75/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.7925 - val_accuracy: 0.8041\n",
            "Epoch 76/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.8099 - val_accuracy: 0.8010\n",
            "Epoch 77/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.7622 - val_accuracy: 0.8102\n",
            "Epoch 78/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.7688 - val_accuracy: 0.8051\n",
            "Epoch 79/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.7548 - val_accuracy: 0.8223\n",
            "Epoch 80/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.7625 - val_accuracy: 0.8071\n",
            "Epoch 81/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.7808 - val_accuracy: 0.8112\n",
            "Epoch 82/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.7622 - val_accuracy: 0.8061\n",
            "Epoch 83/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.7587 - val_accuracy: 0.8102\n",
            "Epoch 84/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.7638 - val_accuracy: 0.8193\n",
            "Epoch 85/150\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 0.0149 - accuracy: 0.9943 - val_loss: 0.8519 - val_accuracy: 0.8071\n",
            "Epoch 86/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.8196 - val_accuracy: 0.8020\n",
            "Epoch 87/150\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 0.0298 - accuracy: 0.9908"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6a7feee0c652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mreset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training log for LSTM-FCN classifier:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m classifier_history = classifier.fit(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mX_train_processed_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_lstmcells = 8\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "classifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(lr=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train_processed_padded,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e9e44",
      "metadata": {
        "id": "598e9e44"
      },
      "source": [
        "## 1dCNN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60c78f9",
      "metadata": {
        "scrolled": true,
        "id": "c60c78f9"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.1 CF search with 1dCNN autoencoder\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0.0001, patience=5, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history[\"val_loss\"])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded"
      ],
      "metadata": {
        "id": "CbU3iaJ021mA"
      },
      "id": "CbU3iaJ021mA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "y_pred_neg = y_pred[:10]\n",
        "print(X_pred_neg.shape)\n",
        "print(y_pred_neg)"
      ],
      "metadata": {
        "id": "EbIsx2ut529Q"
      },
      "id": "EbIsx2ut529Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded[y_pred_classes == neg_label][:10].shape\n"
      ],
      "metadata": {
        "id": "UNgNxBGN2YfP"
      },
      "id": "UNgNxBGN2YfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = y_pred_classes[y_pred_classes==neg_label][:10]\n",
        "y_pred_labels"
      ],
      "metadata": {
        "id": "7Mad6xup3Rh-"
      },
      "id": "7Mad6xup3Rh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "576d45df",
      "metadata": {
        "id": "576d45df"
      },
      "source": [
        "## CF search, original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4184c392",
      "metadata": {
        "id": "4184c392"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    print(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        y_pred_labels,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432b662",
      "metadata": {
        "id": "a432b662"
      },
      "outputs": [],
      "source": [
        "hresult_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d235be",
      "metadata": {
        "id": "82d235be"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6e70d",
      "metadata": {
        "id": "e4e6e70d"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a1f54f",
      "metadata": {
        "id": "76a1f54f"
      },
      "outputs": [],
      "source": [
        "sample_id = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d95cf88",
      "metadata": {
        "id": "0d95cf88"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2be787d",
      "metadata": {
        "id": "b2be787d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', alpha=0.8, label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7586c7",
      "metadata": {
        "id": "4b7586c7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8016f0",
      "metadata": {
        "id": "dd8016f0"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1fda14",
      "metadata": {
        "id": "7f1fda14"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ca1e34",
      "metadata": {
        "id": "87ca1e34"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fd9b35",
      "metadata": {
        "scrolled": false,
        "id": "81fd9b35"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c41fe",
      "metadata": {
        "id": "8b9c41fe"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e21e9e9",
      "metadata": {
        "id": "7e21e9e9"
      },
      "source": [
        "## global, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a08016",
      "metadata": {
        "id": "a1a08016"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453bccf",
      "metadata": {
        "id": "7453bccf"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79652cbd",
      "metadata": {
        "id": "79652cbd"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824621c9",
      "metadata": {
        "id": "824621c9"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32072b",
      "metadata": {
        "id": "0b32072b"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60722cbb",
      "metadata": {
        "id": "60722cbb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376469d",
      "metadata": {
        "id": "d376469d"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e29618",
      "metadata": {
        "id": "f3e29618"
      },
      "outputs": [],
      "source": [
        "from wildboar.explain import *\n",
        "\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        p = self.model.predict(X.reshape(X.shape[0], -1, 1))\n",
        "        return np.argmax(p, axis=1) # I think this would work?\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self.model.fit(X, y)\n",
        "\n",
        "clf = ModelWrapper(classifier)\n",
        "\n",
        "i = IntervalImportance(scoring=\"accuracy\", n_interval=10, random_state=RANDOM_STATE)\n",
        "i.fit(clf, X_train_processed_padded.reshape(X_train_processed_padded.shape[0], -1), y_train_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1f6070",
      "metadata": {
        "id": "ca1f6070"
      },
      "outputs": [],
      "source": [
        "print(i.importances_.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2de732",
      "metadata": {
        "id": "8f2de732"
      },
      "outputs": [],
      "source": [
        "seg_idx = i.intervals_\n",
        "seg_imp = i.importances_.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d7481",
      "metadata": {
        "id": "af6d7481"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 75 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 75)\n",
        "# masking_threshold = np.percentile(i.importances_.mean, 25)\n",
        "print(masking_threshold)\n",
        "masking_idx = np.where(seg_imp >= masking_threshold)\n",
        "print(masking_idx)\n",
        "weighted_steps = np.ones(X_test_processed_padded.shape[1])\n",
        "print(weighted_steps.shape)\n",
        "\n",
        "for start_idx in masking_idx[0]:\n",
        "    weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5214cafb",
      "metadata": {
        "id": "5214cafb"
      },
      "outputs": [],
      "source": [
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63397e5",
      "metadata": {
        "id": "b63397e5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine Noise\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'red' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7276f7af",
      "metadata": {
        "id": "7276f7af"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3609b",
      "metadata": {
        "id": "a3b3609b"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7c5d",
      "metadata": {
        "id": "761e7c5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f6d81",
      "metadata": {
        "id": "f22f6d81"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab66d2",
      "metadata": {
        "id": "c8ab66d2"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ebda23",
      "metadata": {
        "id": "b4ebda23"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c131798",
      "metadata": {
        "id": "0c131798"
      },
      "source": [
        "## local, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9ddb8",
      "metadata": {
        "id": "34f9ddb8"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"local\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076e60",
      "metadata": {
        "id": "58076e60"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2d1b88",
      "metadata": {
        "id": "3c2d1b88"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d03d8fb",
      "metadata": {
        "id": "7d03d8fb"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e12ebf",
      "metadata": {
        "id": "e4e12ebf"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fac5ab",
      "metadata": {
        "id": "38fac5ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc2cd06",
      "metadata": {
        "id": "cdc2cd06"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625853c",
      "metadata": {
        "id": "4625853c"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "seg_imp, seg_idx = LIMESegment(\n",
        "        series,\n",
        "        classifier,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d861a320",
      "metadata": {
        "id": "d861a320"
      },
      "outputs": [],
      "source": [
        "# seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len - padding_size\n",
        "# seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6aeee",
      "metadata": {
        "id": "f2d6aeee"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 25 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 25)\n",
        "masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62df93b",
      "metadata": {
        "id": "f62df93b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.15)#abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a074fc",
      "metadata": {
        "id": "d9a074fc"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "def get_local_weights(input_sample, classifier_model, random_state=None):\n",
        "    n_timesteps, n_dims = input_sample.shape  # n_dims=1\n",
        "    seg_imp, seg_idx = LIMESegment(\n",
        "        input_sample,\n",
        "        classifier_model,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    # calculate the threshold of masking, 25 percentile\n",
        "    masking_threshold = np.percentile(seg_imp, 25)\n",
        "    masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx] : seg_idx[start_idx + 1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, n_dims)\n",
        "    return weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c217473",
      "metadata": {
        "id": "3c217473"
      },
      "outputs": [],
      "source": [
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "step_weights = get_local_weights(\n",
        "    series, classifier, random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ea0acc",
      "metadata": {
        "id": "20ea0acc"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae653d4",
      "metadata": {
        "id": "7ae653d4"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b22c0",
      "metadata": {
        "id": "c64b22c0"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7be967",
      "metadata": {
        "id": "8c7be967"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634c8598",
      "metadata": {
        "id": "634c8598"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfa1633",
      "metadata": {
        "id": "dbfa1633"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85edfa96",
      "metadata": {
        "id": "85edfa96"
      },
      "source": [
        "## uniform, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d50bdde",
      "metadata": {
        "id": "9d50bdde"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec3d99",
      "metadata": {
        "id": "32ec3d99"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097aa798",
      "metadata": {
        "id": "097aa798"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be879d97",
      "metadata": {
        "id": "be879d97"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef86620",
      "metadata": {
        "id": "9ef86620"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ebc45",
      "metadata": {
        "id": "414ebc45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5b38f7",
      "metadata": {
        "id": "9f5b38f7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d76c19",
      "metadata": {
        "id": "a9d76c19"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc9d96",
      "metadata": {
        "id": "1edc9d96"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee7c3a0",
      "metadata": {
        "id": "2ee7c3a0"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e56ef9a",
      "metadata": {
        "id": "3e56ef9a"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbd6994",
      "metadata": {
        "id": "fdbd6994"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873b2a93",
      "metadata": {
        "id": "873b2a93"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds-ext",
      "language": "python",
      "name": "ds-ext"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}