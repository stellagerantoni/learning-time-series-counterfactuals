{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f239ef",
      "metadata": {
        "id": "a0f239ef"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a307b064",
      "metadata": {
        "id": "a307b064",
        "outputId": "7052e59e-6ed0-4b58-a9a0-01b000b8e25d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 219 (delta 62), reused 24 (delta 24), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (219/219), 1.71 MiB | 28.67 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "/content/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        "%cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cd622a74",
      "metadata": {
        "id": "cd622a74"
      },
      "outputs": [],
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ad8718d5",
      "metadata": {
        "id": "ad8718d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a756fb",
      "metadata": {
        "id": "08a756fb"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7845e90e",
      "metadata": {
        "id": "7845e90e",
        "outputId": "14cf8eea-d2f2-4529-a81d-41647ea6fc01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/src\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "%cd src\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ef330b1e",
      "metadata": {
        "id": "ef330b1e"
      },
      "outputs": [],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "80b4f195",
      "metadata": {
        "id": "80b4f195",
        "outputId": "40412f3f-bf0f-4e4f-9fab-25628538985d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "gpu_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a87d6e5f",
      "metadata": {
        "id": "a87d6e5f"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d6ff63c0",
      "metadata": {
        "id": "d6ff63c0"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"FordA\"\n",
        "OUTPUT_FILENAME = \"FordA-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "774a78f4",
      "metadata": {
        "id": "774a78f4"
      },
      "outputs": [],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = -1\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "66181d53",
      "metadata": {
        "id": "66181d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0896cd83-2fd2-49c2-b554-cab8909cb946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=500, padded #timesteps=500.\n"
          ]
        }
      ],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_processed.shape)\n",
        "print(X_train_processed_padded.shape)"
      ],
      "metadata": {
        "id": "-_watlod7tQQ",
        "outputId": "d11b7292-840a-4d8e-cf02-dbfbb8bb01f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-_watlod7tQQ",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4042, 500, 1)\n",
            "(4042, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "03febb4b",
      "metadata": {
        "id": "03febb4b"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f551c9",
      "metadata": {
        "scrolled": true,
        "id": "e8f551c9",
        "outputId": "88c54bfb-7f64-4ad8-fe4d-5a98e90a3c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            " 67/127 [==============>...............] - ETA: 1s - loss: 0.6934 - accuracy: 0.5826"
          ]
        }
      ],
      "source": [
        "n_lstmcells = 8\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "classifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train_processed_padded,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e9e44",
      "metadata": {
        "id": "598e9e44"
      },
      "source": [
        "## 1dCNN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60c78f9",
      "metadata": {
        "scrolled": true,
        "id": "c60c78f9"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.1 CF search with 1dCNN autoencoder\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0.0001, patience=5, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history[\"val_loss\"])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded"
      ],
      "metadata": {
        "id": "CbU3iaJ021mA"
      },
      "id": "CbU3iaJ021mA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "y_pred_neg = y_pred[:10]\n",
        "print(X_pred_neg.shape)\n",
        "print(y_pred_neg)"
      ],
      "metadata": {
        "id": "EbIsx2ut529Q"
      },
      "id": "EbIsx2ut529Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded[y_pred_classes == neg_label][:10].shape\n"
      ],
      "metadata": {
        "id": "UNgNxBGN2YfP"
      },
      "id": "UNgNxBGN2YfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = y_pred_classes[y_pred_classes==neg_label][:10]\n",
        "y_pred_labels"
      ],
      "metadata": {
        "id": "7Mad6xup3Rh-"
      },
      "id": "7Mad6xup3Rh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "576d45df",
      "metadata": {
        "id": "576d45df"
      },
      "source": [
        "## CF search, original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4184c392",
      "metadata": {
        "id": "4184c392"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    print(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        y_pred_labels,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432b662",
      "metadata": {
        "id": "a432b662"
      },
      "outputs": [],
      "source": [
        "hresult_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d235be",
      "metadata": {
        "id": "82d235be"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6e70d",
      "metadata": {
        "id": "e4e6e70d"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a1f54f",
      "metadata": {
        "id": "76a1f54f"
      },
      "outputs": [],
      "source": [
        "sample_id = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d95cf88",
      "metadata": {
        "id": "0d95cf88"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2be787d",
      "metadata": {
        "id": "b2be787d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', alpha=0.8, label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7586c7",
      "metadata": {
        "id": "4b7586c7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8016f0",
      "metadata": {
        "id": "dd8016f0"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1fda14",
      "metadata": {
        "id": "7f1fda14"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ca1e34",
      "metadata": {
        "id": "87ca1e34"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fd9b35",
      "metadata": {
        "scrolled": false,
        "id": "81fd9b35"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c41fe",
      "metadata": {
        "id": "8b9c41fe"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e21e9e9",
      "metadata": {
        "id": "7e21e9e9"
      },
      "source": [
        "## global, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a08016",
      "metadata": {
        "id": "a1a08016"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453bccf",
      "metadata": {
        "id": "7453bccf"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79652cbd",
      "metadata": {
        "id": "79652cbd"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824621c9",
      "metadata": {
        "id": "824621c9"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32072b",
      "metadata": {
        "id": "0b32072b"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60722cbb",
      "metadata": {
        "id": "60722cbb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376469d",
      "metadata": {
        "id": "d376469d"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e29618",
      "metadata": {
        "id": "f3e29618"
      },
      "outputs": [],
      "source": [
        "from wildboar.explain import *\n",
        "\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        p = self.model.predict(X.reshape(X.shape[0], -1, 1))\n",
        "        return np.argmax(p, axis=1) # I think this would work?\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self.model.fit(X, y)\n",
        "\n",
        "clf = ModelWrapper(classifier)\n",
        "\n",
        "i = IntervalImportance(scoring=\"accuracy\", n_interval=10, random_state=RANDOM_STATE)\n",
        "i.fit(clf, X_train_processed_padded.reshape(X_train_processed_padded.shape[0], -1), y_train_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1f6070",
      "metadata": {
        "id": "ca1f6070"
      },
      "outputs": [],
      "source": [
        "print(i.importances_.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2de732",
      "metadata": {
        "id": "8f2de732"
      },
      "outputs": [],
      "source": [
        "seg_idx = i.intervals_\n",
        "seg_imp = i.importances_.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d7481",
      "metadata": {
        "id": "af6d7481"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 75 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 75)\n",
        "# masking_threshold = np.percentile(i.importances_.mean, 25)\n",
        "print(masking_threshold)\n",
        "masking_idx = np.where(seg_imp >= masking_threshold)\n",
        "print(masking_idx)\n",
        "weighted_steps = np.ones(X_test_processed_padded.shape[1])\n",
        "print(weighted_steps.shape)\n",
        "\n",
        "for start_idx in masking_idx[0]:\n",
        "    weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5214cafb",
      "metadata": {
        "id": "5214cafb"
      },
      "outputs": [],
      "source": [
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63397e5",
      "metadata": {
        "id": "b63397e5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine Noise\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'red' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7276f7af",
      "metadata": {
        "id": "7276f7af"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3609b",
      "metadata": {
        "id": "a3b3609b"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7c5d",
      "metadata": {
        "id": "761e7c5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f6d81",
      "metadata": {
        "id": "f22f6d81"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab66d2",
      "metadata": {
        "id": "c8ab66d2"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ebda23",
      "metadata": {
        "id": "b4ebda23"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c131798",
      "metadata": {
        "id": "0c131798"
      },
      "source": [
        "## local, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9ddb8",
      "metadata": {
        "id": "34f9ddb8"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"local\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076e60",
      "metadata": {
        "id": "58076e60"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2d1b88",
      "metadata": {
        "id": "3c2d1b88"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d03d8fb",
      "metadata": {
        "id": "7d03d8fb"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e12ebf",
      "metadata": {
        "id": "e4e12ebf"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fac5ab",
      "metadata": {
        "id": "38fac5ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc2cd06",
      "metadata": {
        "id": "cdc2cd06"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625853c",
      "metadata": {
        "id": "4625853c"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "seg_imp, seg_idx = LIMESegment(\n",
        "        series,\n",
        "        classifier,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d861a320",
      "metadata": {
        "id": "d861a320"
      },
      "outputs": [],
      "source": [
        "# seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len - padding_size\n",
        "# seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6aeee",
      "metadata": {
        "id": "f2d6aeee"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 25 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 25)\n",
        "masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62df93b",
      "metadata": {
        "id": "f62df93b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.15)#abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a074fc",
      "metadata": {
        "id": "d9a074fc"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "def get_local_weights(input_sample, classifier_model, random_state=None):\n",
        "    n_timesteps, n_dims = input_sample.shape  # n_dims=1\n",
        "    seg_imp, seg_idx = LIMESegment(\n",
        "        input_sample,\n",
        "        classifier_model,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    # calculate the threshold of masking, 25 percentile\n",
        "    masking_threshold = np.percentile(seg_imp, 25)\n",
        "    masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx] : seg_idx[start_idx + 1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, n_dims)\n",
        "    return weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c217473",
      "metadata": {
        "id": "3c217473"
      },
      "outputs": [],
      "source": [
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "step_weights = get_local_weights(\n",
        "    series, classifier, random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ea0acc",
      "metadata": {
        "id": "20ea0acc"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae653d4",
      "metadata": {
        "id": "7ae653d4"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b22c0",
      "metadata": {
        "id": "c64b22c0"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7be967",
      "metadata": {
        "id": "8c7be967"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634c8598",
      "metadata": {
        "id": "634c8598"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfa1633",
      "metadata": {
        "id": "dbfa1633"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85edfa96",
      "metadata": {
        "id": "85edfa96"
      },
      "source": [
        "## uniform, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d50bdde",
      "metadata": {
        "id": "9d50bdde"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec3d99",
      "metadata": {
        "id": "32ec3d99"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097aa798",
      "metadata": {
        "id": "097aa798"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be879d97",
      "metadata": {
        "id": "be879d97"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef86620",
      "metadata": {
        "id": "9ef86620"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ebc45",
      "metadata": {
        "id": "414ebc45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5b38f7",
      "metadata": {
        "id": "9f5b38f7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d76c19",
      "metadata": {
        "id": "a9d76c19"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc9d96",
      "metadata": {
        "id": "1edc9d96"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee7c3a0",
      "metadata": {
        "id": "2ee7c3a0"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e56ef9a",
      "metadata": {
        "id": "3e56ef9a"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbd6994",
      "metadata": {
        "id": "fdbd6994"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873b2a93",
      "metadata": {
        "id": "873b2a93"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds-ext",
      "language": "python",
      "name": "ds-ext"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}