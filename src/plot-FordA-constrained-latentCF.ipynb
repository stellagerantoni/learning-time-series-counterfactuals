{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f239ef",
      "metadata": {
        "id": "a0f239ef"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a307b064",
      "metadata": {
        "id": "a307b064",
        "outputId": "63c39451-dcb8-4c77-966d-0366e851ef80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 234 (delta 72), reused 24 (delta 24), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (234/234), 1.72 MiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "/content/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        "%cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd622a74",
      "metadata": {
        "id": "cd622a74"
      },
      "outputs": [],
      "source": [
        "!pip install -q wildboar\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8718d5",
      "metadata": {
        "id": "ad8718d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a756fb",
      "metadata": {
        "id": "08a756fb"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7845e90e",
      "metadata": {
        "id": "7845e90e",
        "outputId": "14cf8eea-d2f2-4529-a81d-41647ea6fc01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/src\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "%cd src\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef330b1e",
      "metadata": {
        "id": "ef330b1e"
      },
      "outputs": [],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b4f195",
      "metadata": {
        "id": "80b4f195",
        "outputId": "40412f3f-bf0f-4e4f-9fab-25628538985d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "gpu_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87d6e5f",
      "metadata": {
        "id": "a87d6e5f"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ff63c0",
      "metadata": {
        "id": "d6ff63c0"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"FordA\"\n",
        "OUTPUT_FILENAME = \"FordA-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774a78f4",
      "metadata": {
        "id": "774a78f4"
      },
      "outputs": [],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = -1\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66181d53",
      "metadata": {
        "id": "66181d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0896cd83-2fd2-49c2-b554-cab8909cb946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pre-processed, original #timesteps=500, padded #timesteps=500.\n"
          ]
        }
      ],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "print(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_processed.shape)\n",
        "print(X_train_processed_padded.shape)"
      ],
      "metadata": {
        "id": "-_watlod7tQQ",
        "outputId": "d11b7292-840a-4d8e-cf02-dbfbb8bb01f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-_watlod7tQQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4042, 500, 1)\n",
            "(4042, 500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03febb4b",
      "metadata": {
        "id": "03febb4b"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f551c9",
      "metadata": {
        "scrolled": true,
        "id": "e8f551c9",
        "outputId": "88c54bfb-7f64-4ad8-fe4d-5a98e90a3c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "127/127 [==============================] - 8s 25ms/step - loss: 0.6543 - accuracy: 0.6366 - val_loss: 0.6943 - val_accuracy: 0.5137\n",
            "Epoch 2/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.5186 - accuracy: 0.7803 - val_loss: 0.6988 - val_accuracy: 0.5137\n",
            "Epoch 3/150\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.4454 - accuracy: 0.8258 - val_loss: 0.6613 - val_accuracy: 0.5726\n",
            "Epoch 4/150\n",
            "127/127 [==============================] - 5s 36ms/step - loss: 0.3712 - accuracy: 0.8674 - val_loss: 0.5557 - val_accuracy: 0.7340\n",
            "Epoch 5/150\n",
            "127/127 [==============================] - 5s 39ms/step - loss: 0.3151 - accuracy: 0.8944 - val_loss: 0.5156 - val_accuracy: 0.7563\n",
            "Epoch 6/150\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 0.2579 - accuracy: 0.9179 - val_loss: 0.4853 - val_accuracy: 0.7716\n",
            "Epoch 7/150\n",
            "127/127 [==============================] - 5s 38ms/step - loss: 0.2224 - accuracy: 0.9305 - val_loss: 0.4932 - val_accuracy: 0.7787\n",
            "Epoch 8/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.1994 - accuracy: 0.9384 - val_loss: 0.4863 - val_accuracy: 0.7939\n",
            "Epoch 9/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.1760 - accuracy: 0.9463 - val_loss: 0.4901 - val_accuracy: 0.7838\n",
            "Epoch 10/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.1577 - accuracy: 0.9527 - val_loss: 0.4736 - val_accuracy: 0.8112\n",
            "Epoch 11/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.1381 - accuracy: 0.9592 - val_loss: 0.4807 - val_accuracy: 0.8041\n",
            "Epoch 12/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.1173 - accuracy: 0.9661 - val_loss: 0.4939 - val_accuracy: 0.7909\n",
            "Epoch 13/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.1084 - accuracy: 0.9723 - val_loss: 0.4733 - val_accuracy: 0.7980\n",
            "Epoch 14/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0998 - accuracy: 0.9723 - val_loss: 0.5284 - val_accuracy: 0.7929\n",
            "Epoch 15/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0808 - accuracy: 0.9800 - val_loss: 0.5111 - val_accuracy: 0.7980\n",
            "Epoch 16/150\n",
            "127/127 [==============================] - 2s 20ms/step - loss: 0.0862 - accuracy: 0.9782 - val_loss: 0.5344 - val_accuracy: 0.7949\n",
            "Epoch 17/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.5357 - val_accuracy: 0.7990\n",
            "Epoch 18/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0707 - accuracy: 0.9812 - val_loss: 0.5658 - val_accuracy: 0.7970\n",
            "Epoch 19/150\n",
            "127/127 [==============================] - 3s 25ms/step - loss: 0.0673 - accuracy: 0.9839 - val_loss: 0.5623 - val_accuracy: 0.7939\n",
            "Epoch 20/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.0568 - accuracy: 0.9876 - val_loss: 0.5681 - val_accuracy: 0.7990\n",
            "Epoch 21/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0644 - accuracy: 0.9839 - val_loss: 0.5512 - val_accuracy: 0.8112\n",
            "Epoch 22/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0506 - accuracy: 0.9859 - val_loss: 0.5766 - val_accuracy: 0.7949\n",
            "Epoch 23/150\n",
            "127/127 [==============================] - 2s 20ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 0.5399 - val_accuracy: 0.8122\n",
            "Epoch 24/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0520 - accuracy: 0.9876 - val_loss: 0.5975 - val_accuracy: 0.7929\n",
            "Epoch 25/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.0379 - accuracy: 0.9931 - val_loss: 0.5675 - val_accuracy: 0.8102\n",
            "Epoch 26/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0544 - accuracy: 0.9832 - val_loss: 0.5619 - val_accuracy: 0.8071\n",
            "Epoch 27/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0371 - accuracy: 0.9913 - val_loss: 0.6093 - val_accuracy: 0.7939\n",
            "Epoch 28/150\n",
            "127/127 [==============================] - 2s 20ms/step - loss: 0.0419 - accuracy: 0.9891 - val_loss: 0.6467 - val_accuracy: 0.7868\n",
            "Epoch 29/150\n",
            "127/127 [==============================] - 3s 26ms/step - loss: 0.0375 - accuracy: 0.9889 - val_loss: 0.6346 - val_accuracy: 0.7888\n",
            "Epoch 30/150\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.5782 - val_accuracy: 0.8081\n",
            "Epoch 31/150\n",
            "127/127 [==============================] - 2s 20ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.5732 - val_accuracy: 0.8071\n",
            "Epoch 32/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0294 - accuracy: 0.9936 - val_loss: 0.6494 - val_accuracy: 0.7848\n",
            "Epoch 33/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.6796 - val_accuracy: 0.7848\n",
            "Epoch 34/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.6318 - val_accuracy: 0.8010\n",
            "Epoch 35/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.0309 - accuracy: 0.9928 - val_loss: 0.6562 - val_accuracy: 0.8010\n",
            "Epoch 36/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.6454 - val_accuracy: 0.7970\n",
            "Epoch 37/150\n",
            "127/127 [==============================] - 3s 21ms/step - loss: 0.0297 - accuracy: 0.9936 - val_loss: 0.6611 - val_accuracy: 0.8051\n",
            "Epoch 38/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.6816 - val_accuracy: 0.7970\n",
            "Epoch 39/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.6742 - val_accuracy: 0.7929\n",
            "Epoch 40/150\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.7054 - val_accuracy: 0.7949\n",
            "Epoch 41/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.7510 - val_accuracy: 0.7858\n",
            "Epoch 42/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.6978 - val_accuracy: 0.7939\n",
            "Epoch 43/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.6673 - val_accuracy: 0.7970\n",
            "Epoch 44/150\n",
            "127/127 [==============================] - 4s 29ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.6745 - val_accuracy: 0.8091\n",
            "Epoch 45/150\n",
            "127/127 [==============================] - 4s 32ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.7037 - val_accuracy: 0.8020\n",
            "Epoch 46/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.7670 - val_accuracy: 0.7939\n",
            "Epoch 47/150\n",
            "127/127 [==============================] - 2s 19ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.7439 - val_accuracy: 0.7898\n",
            "Epoch 48/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.6866 - val_accuracy: 0.8010\n",
            "Epoch 49/150\n",
            "127/127 [==============================] - 3s 27ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.6987 - val_accuracy: 0.8030\n",
            "Epoch 50/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.7047 - val_accuracy: 0.8051\n",
            "Epoch 51/150\n",
            "127/127 [==============================] - 3s 20ms/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.7330 - val_accuracy: 0.7980\n",
            "Epoch 52/150\n",
            "127/127 [==============================] - 2s 20ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.7253 - val_accuracy: 0.8081\n",
            "Epoch 53/150\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.7083 - val_accuracy: 0.8122\n",
            "31/31 [==============================] - 1s 11ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.8103426935232327.\n",
            "Confusion matrix: \n",
            "          Pred:pos  Pred:neg\n",
            "True:pos       356       123\n",
            "True:neg        62       444.\n"
          ]
        }
      ],
      "source": [
        "n_lstmcells = 8\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "classifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train_processed_padded,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e9e44",
      "metadata": {
        "id": "598e9e44"
      },
      "source": [
        "## 1dCNN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60c78f9",
      "metadata": {
        "scrolled": true,
        "id": "c60c78f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83037215-9e58-4faa-9f19-b4d34f86484e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "127/127 [==============================] - 5s 15ms/step - loss: 0.0349 - val_loss: 0.0014\n",
            "Epoch 2/50\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 5.6616e-04 - val_loss: 2.0927e-04\n",
            "Epoch 3/50\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 1.2261e-04 - val_loss: 7.4719e-05\n",
            "Epoch 4/50\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 5.9593e-05 - val_loss: 4.5868e-05\n",
            "Epoch 5/50\n",
            "127/127 [==============================] - 4s 31ms/step - loss: 3.9965e-05 - val_loss: 3.3205e-05\n",
            "Epoch 6/50\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 3.0012e-05 - val_loss: 2.6120e-05\n",
            "Epoch 7/50\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 2.4835e-05 - val_loss: 2.1266e-05\n",
            "Epoch 8/50\n",
            "127/127 [==============================] - 3s 23ms/step - loss: 2.0003e-05 - val_loss: 1.8399e-05\n",
            "1dCNN autoencoder trained, with validation loss: 1.8398768588667735e-05.\n"
          ]
        }
      ],
      "source": [
        "###############################################\n",
        "# ## 2.1 CF search with 1dCNN autoencoder\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0.0001, patience=5, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history[\"val_loss\"])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded"
      ],
      "metadata": {
        "id": "CbU3iaJ021mA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32af475-00b0-4e87-a5da-0894b710fd12"
      },
      "id": "CbU3iaJ021mA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.5295002 ],\n",
              "        [0.49561936],\n",
              "        [0.45857199],\n",
              "        ...,\n",
              "        [0.50469327],\n",
              "        [0.46222401],\n",
              "        [0.42419781]],\n",
              "\n",
              "       [[0.49603076],\n",
              "        [0.46070305],\n",
              "        [0.42359454],\n",
              "        ...,\n",
              "        [0.64260833],\n",
              "        [0.59311292],\n",
              "        [0.53626491]],\n",
              "\n",
              "       [[0.68599255],\n",
              "        [0.61981164],\n",
              "        [0.54309356],\n",
              "        ...,\n",
              "        [0.55381561],\n",
              "        [0.55991609],\n",
              "        [0.56250416]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.56506951],\n",
              "        [0.52409475],\n",
              "        [0.46521129],\n",
              "        ...,\n",
              "        [0.37243351],\n",
              "        [0.37877094],\n",
              "        [0.41603065]],\n",
              "\n",
              "       [[0.47987026],\n",
              "        [0.48958899],\n",
              "        [0.49405112],\n",
              "        ...,\n",
              "        [0.37030868],\n",
              "        [0.34027093],\n",
              "        [0.30653289]],\n",
              "\n",
              "       [[0.61386843],\n",
              "        [0.60788295],\n",
              "        [0.5858564 ],\n",
              "        ...,\n",
              "        [0.64499292],\n",
              "        [0.6222481 ],\n",
              "        [0.59244042]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "y_pred_neg = y_pred[:10]\n",
        "print(X_pred_neg.shape)\n",
        "print(y_pred_neg)"
      ],
      "metadata": {
        "id": "EbIsx2ut529Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90511e32-5cb4-4758-cc88-0014e8fbcaf6"
      },
      "id": "EbIsx2ut529Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 500, 1)\n",
            "[[6.7423157e-02 9.3257684e-01]\n",
            " [1.3417093e-04 9.9986577e-01]\n",
            " [9.9999869e-01 1.2891486e-06]\n",
            " [9.9998534e-01 1.4641894e-05]\n",
            " [2.4169380e-02 9.7583061e-01]\n",
            " [7.8737009e-01 2.1262991e-01]\n",
            " [1.9212101e-05 9.9998081e-01]\n",
            " [1.5944652e-02 9.8405528e-01]\n",
            " [9.8830263e-08 9.9999988e-01]\n",
            " [1.0000000e+00 4.1230429e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_padded[y_pred_classes == neg_label][:10].shape\n"
      ],
      "metadata": {
        "id": "UNgNxBGN2YfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df964366-bc1f-4f99-dbc5-cc706fb7b920"
      },
      "id": "UNgNxBGN2YfP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 500, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = y_pred_classes[y_pred_classes==neg_label][:10]\n",
        "y_pred_labels"
      ],
      "metadata": {
        "id": "7Mad6xup3Rh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63d44a1-8d64-4ba3-da85-9aa07a0bed63"
      },
      "id": "7Mad6xup3Rh-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576d45df",
      "metadata": {
        "id": "576d45df"
      },
      "source": [
        "## CF search, original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4184c392",
      "metadata": {
        "id": "4184c392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11dd197-8c93-4612-8cc5-1898c1d5b53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current prediction margin weight is 1.\n",
            "======================== CF search started, with lr=0.0001.\n",
            "1 samples been transformed.\n"
          ]
        }
      ],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    print(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        y_pred_labels,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate2(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432b662",
      "metadata": {
        "id": "a432b662"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d235be",
      "metadata": {
        "id": "82d235be"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6e70d",
      "metadata": {
        "id": "e4e6e70d"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a1f54f",
      "metadata": {
        "id": "76a1f54f"
      },
      "outputs": [],
      "source": [
        "sample_id = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d95cf88",
      "metadata": {
        "id": "0d95cf88"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2be787d",
      "metadata": {
        "id": "b2be787d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', alpha=0.8, label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7586c7",
      "metadata": {
        "id": "4b7586c7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8016f0",
      "metadata": {
        "id": "dd8016f0"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1fda14",
      "metadata": {
        "id": "7f1fda14"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ca1e34",
      "metadata": {
        "id": "87ca1e34"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fd9b35",
      "metadata": {
        "scrolled": false,
        "id": "81fd9b35"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c41fe",
      "metadata": {
        "id": "8b9c41fe"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e21e9e9",
      "metadata": {
        "id": "7e21e9e9"
      },
      "source": [
        "## global, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a08016",
      "metadata": {
        "id": "a1a08016"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453bccf",
      "metadata": {
        "id": "7453bccf"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79652cbd",
      "metadata": {
        "id": "79652cbd"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824621c9",
      "metadata": {
        "id": "824621c9"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32072b",
      "metadata": {
        "id": "0b32072b"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60722cbb",
      "metadata": {
        "id": "60722cbb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376469d",
      "metadata": {
        "id": "d376469d"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e29618",
      "metadata": {
        "id": "f3e29618"
      },
      "outputs": [],
      "source": [
        "from wildboar.explain import *\n",
        "\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        p = self.model.predict(X.reshape(X.shape[0], -1, 1))\n",
        "        return np.argmax(p, axis=1) # I think this would work?\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self.model.fit(X, y)\n",
        "\n",
        "clf = ModelWrapper(classifier)\n",
        "\n",
        "i = IntervalImportance(scoring=\"accuracy\", n_interval=10, random_state=RANDOM_STATE)\n",
        "i.fit(clf, X_train_processed_padded.reshape(X_train_processed_padded.shape[0], -1), y_train_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1f6070",
      "metadata": {
        "id": "ca1f6070"
      },
      "outputs": [],
      "source": [
        "print(i.importances_.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2de732",
      "metadata": {
        "id": "8f2de732"
      },
      "outputs": [],
      "source": [
        "seg_idx = i.intervals_\n",
        "seg_imp = i.importances_.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d7481",
      "metadata": {
        "id": "af6d7481"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 75 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 75)\n",
        "# masking_threshold = np.percentile(i.importances_.mean, 25)\n",
        "print(masking_threshold)\n",
        "masking_idx = np.where(seg_imp >= masking_threshold)\n",
        "print(masking_idx)\n",
        "weighted_steps = np.ones(X_test_processed_padded.shape[1])\n",
        "print(weighted_steps.shape)\n",
        "\n",
        "for start_idx in masking_idx[0]:\n",
        "    weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5214cafb",
      "metadata": {
        "id": "5214cafb"
      },
      "outputs": [],
      "source": [
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63397e5",
      "metadata": {
        "id": "b63397e5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine Noise\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'red' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7276f7af",
      "metadata": {
        "id": "7276f7af"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3609b",
      "metadata": {
        "id": "a3b3609b"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7c5d",
      "metadata": {
        "id": "761e7c5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f6d81",
      "metadata": {
        "id": "f22f6d81"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab66d2",
      "metadata": {
        "id": "c8ab66d2"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ebda23",
      "metadata": {
        "id": "b4ebda23"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c131798",
      "metadata": {
        "id": "0c131798"
      },
      "source": [
        "## local, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9ddb8",
      "metadata": {
        "id": "34f9ddb8"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"local\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076e60",
      "metadata": {
        "id": "58076e60"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2d1b88",
      "metadata": {
        "id": "3c2d1b88"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d03d8fb",
      "metadata": {
        "id": "7d03d8fb"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e12ebf",
      "metadata": {
        "id": "e4e12ebf"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fac5ab",
      "metadata": {
        "id": "38fac5ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc2cd06",
      "metadata": {
        "id": "cdc2cd06"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625853c",
      "metadata": {
        "id": "4625853c"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "seg_imp, seg_idx = LIMESegment(\n",
        "        series,\n",
        "        classifier,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d861a320",
      "metadata": {
        "id": "d861a320"
      },
      "outputs": [],
      "source": [
        "# seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len - padding_size\n",
        "# seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6aeee",
      "metadata": {
        "id": "f2d6aeee"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 25 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 25)\n",
        "masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62df93b",
      "metadata": {
        "id": "f62df93b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Engine noise\")\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.15)#abs(weight))\n",
        "\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a074fc",
      "metadata": {
        "id": "d9a074fc"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "def get_local_weights(input_sample, classifier_model, random_state=None):\n",
        "    n_timesteps, n_dims = input_sample.shape  # n_dims=1\n",
        "    seg_imp, seg_idx = LIMESegment(\n",
        "        input_sample,\n",
        "        classifier_model,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    # calculate the threshold of masking, 25 percentile\n",
        "    masking_threshold = np.percentile(seg_imp, 25)\n",
        "    masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx] : seg_idx[start_idx + 1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, n_dims)\n",
        "    return weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c217473",
      "metadata": {
        "id": "3c217473"
      },
      "outputs": [],
      "source": [
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "step_weights = get_local_weights(\n",
        "    series, classifier, random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ea0acc",
      "metadata": {
        "id": "20ea0acc"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae653d4",
      "metadata": {
        "id": "7ae653d4"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b22c0",
      "metadata": {
        "id": "c64b22c0"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7be967",
      "metadata": {
        "id": "8c7be967"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634c8598",
      "metadata": {
        "id": "634c8598"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfa1633",
      "metadata": {
        "id": "dbfa1633"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85edfa96",
      "metadata": {
        "id": "85edfa96"
      },
      "source": [
        "## uniform, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d50bdde",
      "metadata": {
        "id": "9d50bdde"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec3d99",
      "metadata": {
        "id": "32ec3d99"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097aa798",
      "metadata": {
        "id": "097aa798"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be879d97",
      "metadata": {
        "id": "be879d97"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef86620",
      "metadata": {
        "id": "9ef86620"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ebc45",
      "metadata": {
        "id": "414ebc45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5b38f7",
      "metadata": {
        "id": "9f5b38f7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d76c19",
      "metadata": {
        "id": "a9d76c19"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc9d96",
      "metadata": {
        "id": "1edc9d96"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee7c3a0",
      "metadata": {
        "id": "2ee7c3a0"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e56ef9a",
      "metadata": {
        "id": "3e56ef9a"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbd6994",
      "metadata": {
        "id": "fdbd6994"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873b2a93",
      "metadata": {
        "id": "873b2a93"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds-ext",
      "language": "python",
      "name": "ds-ext"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}