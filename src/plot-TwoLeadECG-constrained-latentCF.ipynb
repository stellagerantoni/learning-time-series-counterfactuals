{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f239ef",
      "metadata": {
        "id": "a0f239ef"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a307b064",
      "metadata": {
        "id": "a307b064",
        "outputId": "0a433528-21d7-44f5-85aa-3843c41bb416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'learning-time-series-counterfactuals' already exists and is not an empty directory.\n",
            "/content/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        " ! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        " %cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cd622a74",
      "metadata": {
        "id": "cd622a74"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n",
        "!pip install -q wildboar\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ad8718d5",
      "metadata": {
        "id": "ad8718d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "772e4dd0",
      "metadata": {
        "id": "772e4dd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "08a756fb",
      "metadata": {
        "id": "08a756fb"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7845e90e",
      "metadata": {
        "id": "7845e90e"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ef330b1e",
      "metadata": {
        "id": "ef330b1e"
      },
      "outputs": [],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "80b4f195",
      "metadata": {
        "id": "80b4f195",
        "outputId": "484b021f-76a5-40c0-8485-3ce22cbd1cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "gpu_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a87d6e5f",
      "metadata": {
        "id": "a87d6e5f"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d6ff63c0",
      "metadata": {
        "id": "d6ff63c0"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"TwoLeadECG\"\n",
        "OUTPUT_FILENAME = \"twolead-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "774a78f4",
      "metadata": {
        "id": "774a78f4"
      },
      "outputs": [],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = 2\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "66181d53",
      "metadata": {
        "id": "66181d53"
      },
      "outputs": [],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "logger.info(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "03febb4b",
      "metadata": {
        "id": "03febb4b"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e8f551c9",
      "metadata": {
        "scrolled": true,
        "id": "e8f551c9",
        "outputId": "e7e3885a-e54d-4072-e075-316b13307f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 10s 72ms/step - loss: 0.2356 - accuracy: 0.9172 - val_loss: 0.6836 - val_accuracy: 0.4979\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 2s 62ms/step - loss: 0.0863 - accuracy: 0.9817 - val_loss: 0.6867 - val_accuracy: 0.5021\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 2s 78ms/step - loss: 0.0554 - accuracy: 0.9903 - val_loss: 0.6854 - val_accuracy: 0.5021\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 2s 74ms/step - loss: 0.0345 - accuracy: 0.9946 - val_loss: 0.7018 - val_accuracy: 0.5021\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.7610 - val_accuracy: 0.5021\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0346 - accuracy: 0.9946 - val_loss: 0.6881 - val_accuracy: 0.5021\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 0.5328 - val_accuracy: 0.6695\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.8798\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.4989 - val_accuracy: 0.6867\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.0423 - accuracy: 0.9903 - val_loss: 0.8402 - val_accuracy: 0.6223\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 2s 62ms/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.3756 - val_accuracy: 0.8326\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 2s 77ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.2838 - val_accuracy: 0.8884\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 2s 76ms/step - loss: 0.0325 - accuracy: 0.9925 - val_loss: 0.2392 - val_accuracy: 0.9270\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.2993 - val_accuracy: 0.8584\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.4272 - val_accuracy: 0.7940\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.0867 - val_accuracy: 0.9871\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0861 - val_accuracy: 0.9828\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.1372 - val_accuracy: 0.9571\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.2217 - val_accuracy: 0.9099\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 2s 63ms/step - loss: 0.0516 - accuracy: 0.9839 - val_loss: 3.9495 - val_accuracy: 0.4979\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 2s 77ms/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 0.1784 - val_accuracy: 0.9356\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 2s 75ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.8528 - val_accuracy: 0.6996\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.0172 - accuracy: 0.9989 - val_loss: 0.6459 - val_accuracy: 0.7167\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 2.3667 - val_accuracy: 0.6094\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0325 - accuracy: 0.9946 - val_loss: 3.7147 - val_accuracy: 0.5536\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.0355 - accuracy: 0.9903 - val_loss: 0.6884 - val_accuracy: 0.7811\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.0187 - accuracy: 0.9978 - val_loss: 0.2146 - val_accuracy: 0.8927\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.2871 - val_accuracy: 0.8670\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0330 - accuracy: 0.9914 - val_loss: 1.1240 - val_accuracy: 0.7382\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 2s 78ms/step - loss: 0.0209 - accuracy: 0.9978 - val_loss: 0.3461 - val_accuracy: 0.8369\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 2s 79ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.3706 - val_accuracy: 0.8369\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0676 - val_accuracy: 0.9828\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.1141 - val_accuracy: 0.9657\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.3474 - val_accuracy: 0.8326\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0266 - accuracy: 0.9957 - val_loss: 0.0313 - val_accuracy: 0.9871\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.4837 - val_accuracy: 0.8283\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 2s 75ms/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.2022 - val_accuracy: 0.9227\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 2s 78ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.1350 - val_accuracy: 0.9614\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0336 - accuracy: 0.9914 - val_loss: 0.2366 - val_accuracy: 0.9142\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0535 - accuracy: 0.9849 - val_loss: 0.1836 - val_accuracy: 0.9270\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0187 - accuracy: 0.9978 - val_loss: 0.4012 - val_accuracy: 0.8326\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0634 - accuracy: 0.9785 - val_loss: 0.2292 - val_accuracy: 0.9056\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 0.3749 - val_accuracy: 0.8369\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 0.0818 - val_accuracy: 0.9742\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 2s 79ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0262 - val_accuracy: 0.9914\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 2s 79ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.3201 - val_accuracy: 0.8627\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.2035 - val_accuracy: 0.9270\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1014 - val_accuracy: 0.9700\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0128 - val_accuracy: 0.9914\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0330 - val_accuracy: 0.9914\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0300 - val_accuracy: 0.9914\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0172 - val_accuracy: 0.9914\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 2s 74ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0427 - val_accuracy: 0.9914\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 2s 81ms/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 0.0383 - val_accuracy: 0.9914\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 2s 82ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.0469 - val_accuracy: 0.9914\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.2872 - val_accuracy: 0.8798\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.1040 - val_accuracy: 0.9742\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0149 - val_accuracy: 0.9914\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 0.0709 - val_accuracy: 0.9871\n",
            "8/8 [==============================] - 1s 10ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 1.0.\n",
            "Confusion matrix: \n",
            "          Pred:pos  Pred:neg\n",
            "True:pos       117         0\n",
            "True:neg         0       116.\n"
          ]
        }
      ],
      "source": [
        "n_lstmcells = 8\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "classifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train_processed_padded,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e9e44",
      "metadata": {
        "id": "598e9e44"
      },
      "source": [
        "## 1dCNN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c60c78f9",
      "metadata": {
        "scrolled": true,
        "id": "c60c78f9",
        "outputId": "feaba69b-4b02-43c2-bb44-4471e71fc439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 3s 41ms/step - loss: 0.1719 - val_loss: 0.0260\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0146 - val_loss: 0.0102\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0078 - val_loss: 0.0049\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0036 - val_loss: 0.0026\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 9.2207e-04 - val_loss: 6.4904e-04\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 5.2869e-04 - val_loss: 4.1440e-04\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 3.7388e-04 - val_loss: 3.1025e-04\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 2.9148e-04 - val_loss: 2.6876e-04\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 2.5150e-04 - val_loss: 2.2561e-04\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 2.1646e-04 - val_loss: 1.9662e-04\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 1.8945e-04 - val_loss: 1.7649e-04\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 1.6997e-04 - val_loss: 1.6578e-04\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.5550e-04 - val_loss: 1.4806e-04\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.4462e-04 - val_loss: 1.3795e-04\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 1.3527e-04 - val_loss: 1.3040e-04\n",
            "1dCNN autoencoder trained, with validation loss: 0.0001303995231864974.\n"
          ]
        }
      ],
      "source": [
        "###############################################\n",
        "# ## 2.1 CF search with 1dCNN autoencoder\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0.0001, patience=5, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history[\"val_loss\"])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from wildboar.explain import IntervalImportance\n",
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"global\"\n",
        "i = IntervalImportance(scoring=\"accuracy\", random_state=None)\n",
        "i.n_intervals\n"
      ],
      "metadata": {
        "id": "vATtHcZeF7BS",
        "outputId": "e1fc9527-17a4-43a0-acf5-7b2dee8e1b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "id": "vATtHcZeF7BS",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sqrt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576d45df",
      "metadata": {
        "id": "576d45df"
      },
      "source": [
        "## CF search, original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4184c392",
      "metadata": {
        "id": "4184c392",
        "outputId": "739fabe9-be75-444c-8940-01fd64d1618b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3c49463cfc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"global\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     step_weights = get_global_weights(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX_train_processed_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_train_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./learning-time-series-counterfactuals/src/_guided.py\u001b[0m in \u001b[0;36mget_global_weights\u001b[0;34m(input_samples, input_labels, classifier_model, random_state)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntervalImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_interval'"
          ]
        }
      ],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "  #in get_global_weights, in IntervalImportance n_intervals=10 but i erased it! not shure.\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432b662",
      "metadata": {
        "id": "a432b662"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d235be",
      "metadata": {
        "id": "82d235be"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6e70d",
      "metadata": {
        "id": "e4e6e70d"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a1f54f",
      "metadata": {
        "id": "76a1f54f"
      },
      "outputs": [],
      "source": [
        "sample_id = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d95cf88",
      "metadata": {
        "id": "0d95cf88"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2be787d",
      "metadata": {
        "id": "b2be787d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "color = 'lightcoral' # if weight < 0 else 'green' \n",
        "plt.axvspan(0, 82, color=color, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7586c7",
      "metadata": {
        "id": "4b7586c7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8016f0",
      "metadata": {
        "id": "dd8016f0"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1fda14",
      "metadata": {
        "id": "7f1fda14"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ca1e34",
      "metadata": {
        "id": "87ca1e34"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fd9b35",
      "metadata": {
        "scrolled": false,
        "id": "81fd9b35"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "color = 'lightcoral' # if weight < 0 else 'green' \n",
        "plt.axvspan(0, 82, color=color, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c41fe",
      "metadata": {
        "id": "8b9c41fe"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e21e9e9",
      "metadata": {
        "id": "7e21e9e9"
      },
      "source": [
        "## global, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a08016",
      "metadata": {
        "id": "a1a08016"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453bccf",
      "metadata": {
        "id": "7453bccf"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79652cbd",
      "metadata": {
        "id": "79652cbd"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824621c9",
      "metadata": {
        "id": "824621c9"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32072b",
      "metadata": {
        "id": "0b32072b"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60722cbb",
      "metadata": {
        "id": "60722cbb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376469d",
      "metadata": {
        "id": "d376469d"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e29618",
      "metadata": {
        "id": "f3e29618"
      },
      "outputs": [],
      "source": [
        "from wildboar.explain import *\n",
        "\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        p = self.model.predict(X.reshape(X.shape[0], -1, 1))\n",
        "        return np.argmax(p, axis=1) # I think this would work?\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self.model.fit(X, y)\n",
        "\n",
        "clf = ModelWrapper(classifier)\n",
        "\n",
        "i = IntervalImportance(scoring=\"accuracy\", n_interval=10, random_state=RANDOM_STATE)\n",
        "i.fit(clf, X_train_processed_padded.reshape(X_train_processed_padded.shape[0], -1), y_train_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1f6070",
      "metadata": {
        "id": "ca1f6070"
      },
      "outputs": [],
      "source": [
        "print(i.importances_.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2de732",
      "metadata": {
        "id": "8f2de732"
      },
      "outputs": [],
      "source": [
        "seg_idx = i.intervals_\n",
        "seg_imp = i.importances_.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d7481",
      "metadata": {
        "id": "af6d7481"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 75 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 75)\n",
        "# masking_threshold = np.percentile(i.importances_.mean, 25)\n",
        "print(masking_threshold)\n",
        "masking_idx = np.where(seg_imp >= masking_threshold)\n",
        "print(masking_idx)\n",
        "weighted_steps = np.ones(X_test_processed_padded.shape[1])\n",
        "print(weighted_steps.shape)\n",
        "\n",
        "for start_idx in masking_idx[0]:\n",
        "    weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5214cafb",
      "metadata": {
        "id": "5214cafb"
      },
      "outputs": [],
      "source": [
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63397e5",
      "metadata": {
        "id": "b63397e5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight)*0.5)\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7276f7af",
      "metadata": {
        "id": "7276f7af"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3609b",
      "metadata": {
        "id": "a3b3609b"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7c5d",
      "metadata": {
        "id": "761e7c5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e17b16d",
      "metadata": {
        "id": "9e17b16d"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight)*0.5)\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f6d81",
      "metadata": {
        "id": "f22f6d81"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab66d2",
      "metadata": {
        "id": "c8ab66d2"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ebda23",
      "metadata": {
        "id": "b4ebda23"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c131798",
      "metadata": {
        "id": "0c131798"
      },
      "source": [
        "## local, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9ddb8",
      "metadata": {
        "id": "34f9ddb8"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"local\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076e60",
      "metadata": {
        "id": "58076e60"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2d1b88",
      "metadata": {
        "id": "3c2d1b88"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d03d8fb",
      "metadata": {
        "id": "7d03d8fb"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e12ebf",
      "metadata": {
        "id": "e4e12ebf"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fac5ab",
      "metadata": {
        "id": "38fac5ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc2cd06",
      "metadata": {
        "id": "cdc2cd06"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625853c",
      "metadata": {
        "id": "4625853c"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "seg_imp, seg_idx = LIMESegment(\n",
        "        series,\n",
        "        classifier,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d861a320",
      "metadata": {
        "id": "d861a320"
      },
      "outputs": [],
      "source": [
        "# seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len - padding_size\n",
        "# seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6aeee",
      "metadata": {
        "id": "f2d6aeee"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 25 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 25)\n",
        "masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62df93b",
      "metadata": {
        "id": "f62df93b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.11)#abs(weight))\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a074fc",
      "metadata": {
        "id": "d9a074fc"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "def get_local_weights(input_sample, classifier_model, random_state=None):\n",
        "    n_timesteps, n_dims = input_sample.shape  # n_dims=1\n",
        "    seg_imp, seg_idx = LIMESegment(\n",
        "        input_sample,\n",
        "        classifier_model,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    # calculate the threshold of masking, 25 percentile\n",
        "    masking_threshold = np.percentile(seg_imp, 25)\n",
        "    masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx] : seg_idx[start_idx + 1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, n_dims)\n",
        "    return weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c217473",
      "metadata": {
        "id": "3c217473"
      },
      "outputs": [],
      "source": [
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "step_weights = get_local_weights(\n",
        "    series, classifier, random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ea0acc",
      "metadata": {
        "id": "20ea0acc"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae653d4",
      "metadata": {
        "id": "7ae653d4"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b22c0",
      "metadata": {
        "id": "c64b22c0"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7be967",
      "metadata": {
        "id": "8c7be967"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed5b906",
      "metadata": {
        "id": "5ed5b906"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.11)#abs(weight))\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634c8598",
      "metadata": {
        "id": "634c8598"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfa1633",
      "metadata": {
        "id": "dbfa1633"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85edfa96",
      "metadata": {
        "id": "85edfa96"
      },
      "source": [
        "## uniform, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d50bdde",
      "metadata": {
        "id": "9d50bdde"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec3d99",
      "metadata": {
        "id": "32ec3d99"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097aa798",
      "metadata": {
        "id": "097aa798"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be879d97",
      "metadata": {
        "id": "be879d97"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef86620",
      "metadata": {
        "id": "9ef86620"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ebc45",
      "metadata": {
        "id": "414ebc45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5b38f7",
      "metadata": {
        "id": "9f5b38f7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d76c19",
      "metadata": {
        "id": "a9d76c19"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc9d96",
      "metadata": {
        "id": "1edc9d96"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee7c3a0",
      "metadata": {
        "id": "2ee7c3a0"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e56ef9a",
      "metadata": {
        "id": "3e56ef9a"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbd6994",
      "metadata": {
        "id": "fdbd6994"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873b2a93",
      "metadata": {
        "id": "873b2a93"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds-ext",
      "language": "python",
      "name": "ds-ext"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}