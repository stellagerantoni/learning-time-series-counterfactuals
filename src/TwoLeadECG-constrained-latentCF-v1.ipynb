{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d1f78c2",
      "metadata": {
        "id": "2d1f78c2"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "73286d25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73286d25",
        "outputId": "14bb9dcf-a919-4ee2-eaac-90ac2729683b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 147 (delta 82), reused 107 (delta 48), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (147/147), 1.45 MiB | 1.65 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "/content/learning-time-series-counterfactuals/src/LIMESegment/Utils/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        " ! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        " %cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e2d8f2dc",
      "metadata": {
        "id": "e2d8f2dc"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n",
        "!pip install -q wildboar\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e955a6e8",
      "metadata": {
        "id": "e955a6e8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307ebbad",
      "metadata": {
        "id": "307ebbad"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "da78e0e8",
      "metadata": {
        "id": "da78e0e8"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                             find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bdac5a53",
      "metadata": {
        "id": "bdac5a53"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "79751faf",
      "metadata": {
        "id": "79751faf"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"TwoLeadECG\"\n",
        "OUTPUT_FILENAME = \"twolead-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "255ed3dc",
      "metadata": {
        "id": "255ed3dc"
      },
      "outputs": [],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = 2\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "398b9372",
      "metadata": {
        "id": "398b9372"
      },
      "outputs": [],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "logger.info(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2a9f72b9",
      "metadata": {
        "id": "2a9f72b9"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "bf7b163a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf7b163a",
        "outputId": "c1891c20-33dd-44e8-8098-74ac674e5dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 4s 49ms/step - loss: 0.1719 - val_loss: 0.0260\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0146 - val_loss: 0.0102\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.0078 - val_loss: 0.0049\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.0036 - val_loss: 0.0026\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 9.2207e-04 - val_loss: 6.4904e-04\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 5.2869e-04 - val_loss: 4.1440e-04\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 3.7388e-04 - val_loss: 3.1025e-04\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 2.9148e-04 - val_loss: 2.6876e-04\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 2.5150e-04 - val_loss: 2.2561e-04\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 2.1646e-04 - val_loss: 1.9662e-04\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 1.8945e-04 - val_loss: 1.7649e-04\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 1.6997e-04 - val_loss: 1.6578e-04\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 1.5550e-04 - val_loss: 1.4806e-04\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 1.4462e-04 - val_loss: 1.3795e-04\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 1.3527e-04 - val_loss: 1.3040e-04\n"
          ]
        }
      ],
      "source": [
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.1 1dCNN autoencoder + 1dCNN classifier\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\") \n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded, \n",
        "    X_train_processed_padded, \n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True, \n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "logger.info(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "85274cc7",
      "metadata": {
        "id": "85274cc7"
      },
      "outputs": [],
      "source": [
        "def Classifier(n_timesteps, n_features, n_output=2, n_conv_layers=1, add_dense_layer=True):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "    inputs = keras.Input(shape=(n_timesteps, n_features), dtype=\"float32\")\n",
        "    \n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128)(inputs)\n",
        "    else: \n",
        "        x = inputs\n",
        "    \n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(n_output, activation='softmax')(x)\n",
        "    classifier = keras.Model(inputs, outputs)\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "81b59010",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81b59010",
        "outputId": "0ae70610-e0fd-49d6-d5b2-2229515e329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 2s 39ms/step - loss: 0.6109 - accuracy: 0.6957 - val_loss: 0.7348 - val_accuracy: 0.4979\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4267 - accuracy: 0.9118 - val_loss: 0.8707 - val_accuracy: 0.4979\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.3184 - accuracy: 0.9398 - val_loss: 0.9401 - val_accuracy: 0.4979\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2255 - accuracy: 0.9774 - val_loss: 0.8957 - val_accuracy: 0.4979\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.1767 - accuracy: 0.9839 - val_loss: 0.9709 - val_accuracy: 0.4979\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.1365 - accuracy: 0.9914 - val_loss: 0.8328 - val_accuracy: 0.5021\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1101 - accuracy: 0.9903 - val_loss: 0.6245 - val_accuracy: 0.6094\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 2s 65ms/step - loss: 0.0899 - accuracy: 0.9935 - val_loss: 0.4383 - val_accuracy: 0.7983\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 2s 68ms/step - loss: 0.0764 - accuracy: 0.9946 - val_loss: 0.3188 - val_accuracy: 0.9056\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 2s 64ms/step - loss: 0.0704 - accuracy: 0.9925 - val_loss: 0.2796 - val_accuracy: 0.8841\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0598 - accuracy: 0.9946 - val_loss: 0.2321 - val_accuracy: 0.8970\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0515 - accuracy: 0.9925 - val_loss: 0.2192 - val_accuracy: 0.9185\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.0456 - accuracy: 0.9968 - val_loss: 0.1600 - val_accuracy: 0.9614\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0401 - accuracy: 0.9968 - val_loss: 0.1351 - val_accuracy: 0.9785\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0363 - accuracy: 0.9978 - val_loss: 0.1386 - val_accuracy: 0.9528\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0364 - accuracy: 0.9978 - val_loss: 0.1368 - val_accuracy: 0.9485\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0310 - accuracy: 0.9989 - val_loss: 0.1856 - val_accuracy: 0.9142\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 2s 65ms/step - loss: 0.0352 - accuracy: 0.9935 - val_loss: 0.2302 - val_accuracy: 0.9013\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.0352 - accuracy: 0.9946 - val_loss: 0.3949 - val_accuracy: 0.8283\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 2s 74ms/step - loss: 0.0240 - accuracy: 0.9989 - val_loss: 0.0862 - val_accuracy: 0.9828\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 2s 82ms/step - loss: 0.0246 - accuracy: 0.9978 - val_loss: 0.1154 - val_accuracy: 0.9657\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9828\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 2s 67ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9828\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 2s 69ms/step - loss: 0.0222 - accuracy: 0.9968 - val_loss: 0.2638 - val_accuracy: 0.8841\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 2s 63ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9957\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 2s 62ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9871\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 3s 90ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9828\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 3s 94ms/step - loss: 0.0132 - accuracy: 0.9989 - val_loss: 0.2379 - val_accuracy: 0.8755\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 2s 82ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9957\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 2s 61ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 2s 66ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9957\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 2s 70ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.8927\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 2s 68ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9914\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 2s 72ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9785\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 2s 78ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9957\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 3s 88ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9871\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 2s 68ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9828\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9957\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9957\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 2s 63ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9957\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9957\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 2s 79ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9957\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 2s 75ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9957\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 2s 65ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9957\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9957\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9914\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9957\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9957\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9957\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.8927\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9957\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9957\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9957\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9957\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9957\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9957\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9914\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "shallow_cnn = True\n",
        "# ### 1dCNN classifier\n",
        "if shallow_cnn == True:\n",
        "    logger.info(f\"Check shallow_cnn argument={shallow_cnn}, use the shallow structure.\")\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=1, add_dense_layer=True) # shallow CNN for small data size\n",
        "else:\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=3, add_dense_layer=False) # deeper CNN layers for data with larger size\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN classifier:\")\n",
        "classifier_history = classifier.fit(X_train_processed_padded, \n",
        "        y_train, \n",
        "        epochs=150,\n",
        "        batch_size=32,\n",
        "        shuffle=True, \n",
        "        verbose=True, \n",
        "        validation_data=(X_test_processed_padded, y_test),\n",
        "        callbacks=[early_stopping_accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3f69f78d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "3f69f78d",
        "outputId": "fe809854-23f3-4f43-87b9-3ccc271b5969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Pred:pos  Pred:neg\n",
              "True:pos       117         0\n",
              "True:neg         0       116"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ccb404a-40f6-4498-8902-7400e464e7ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred:pos</th>\n",
              "      <th>Pred:neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True:pos</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True:neg</th>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ccb404a-40f6-4498-8902-7400e464e7ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ccb404a-40f6-4498-8902-7400e464e7ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ccb404a-40f6-4498-8902-7400e464e7ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "# y_pred_classes = np.array([1 if pred > 0.5 else 0 for pred in y_pred])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "logger.info(f\"1dCNN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "        confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "        index=['True:pos', 'True:neg'], \n",
        "        columns=['Pred:pos', 'Pred:neg']\n",
        "    )\n",
        "confusion_matrix_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c159d8",
      "metadata": {
        "id": "e2c159d8"
      },
      "source": [
        "## Get LIME local weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f7ddba00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ddba00",
        "outputId": "c642b25e-dd28-487c-f2ce-26fcbc6498c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/src/LIMESegment/Utils/learning-time-series-counterfactuals/src/LIMESegment/Utils\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../LIMESegment/Utils/')\n",
        "%cd src/LIMESegment/Utils/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "523baa28",
      "metadata": {
        "id": "523baa28"
      },
      "outputs": [],
      "source": [
        "from explanations import LIMESegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f59a1c92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f59a1c92",
        "outputId": "525f16ee-9ebf-4f09-e631-5981a0493e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "idx = 2 # explained instance\n",
        "series = X_test_processed_padded[idx]\n",
        "print(y_pred_classes[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0618da3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0618da3b",
        "outputId": "a8be0ead-8f62-4d25-c495-d00dbd9dfa87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.0173028 ,  0.48571366, -0.04890356, -0.41467095,  0.07317616,\n",
              "        -0.1646627 , -0.1737599 ,  0.00528451, -0.02162884,  0.00988812,\n",
              "        -0.08102037]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "\"\"\"\n",
        "# parameters\n",
        "ts: TS array of shape T x 1 where T is length of time series\n",
        "model: Trained model on dataset array of shape n x T x 1\n",
        "model_type: String indicating if classificaton model produces binary output \"class\" or probability output \"proba\", default \"class\"\n",
        "distance: Distance metric to be used by LIMESegment default is 'dtw'\n",
        "window_size: Window size to be used by NNSegment default is T/5\n",
        "cp: Number of change points to be determinded by NNSegment default is 3\n",
        "f: Frequency parameter for RBP default is T/10\n",
        "\"\"\"\n",
        "\n",
        "explanations = LIMESegment(series, classifier, model_type='proba', cp=10, window_size=10)\n",
        "explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "188b89bb",
      "metadata": {
        "id": "188b89bb"
      },
      "outputs": [],
      "source": [
        "seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "56c277ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56c277ac",
        "outputId": "ccdbb783-7f84-4bed-8231-2ed7cb32373d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "series.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "b22c925a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "b22c925a",
        "outputId": "5d685abf-a393-41d4-b16f-b3ed64957e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0, 5: -0.017302798814710918\n",
            "5, 13: 0.48571365887689044\n",
            "13, 19: -0.04890356206898117\n",
            "19, 30: -0.4146709526951232\n",
            "30, 40: 0.07317615798844683\n",
            "40, 48: -0.16466270358846571\n",
            "48, 53: -0.17375989852533663\n",
            "53, 58: 0.005284514653285567\n",
            "58, 66: -0.021628838089892365\n",
            "66, 72: 0.009888122441767289\n",
            "72, 84: -0.08102036634589747\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "plt.plot(series, color='b', label='Explained instance')\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "plt.legend(loc='lower left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    color = 'red' if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "74485f03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74485f03",
        "outputId": "0007e3cb-47f5-4004-f619-fa65482241ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "check = np.where(seg_imp >= 0.01) # seg_imp >= 0.01 or 0.1\n",
        "check[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "32813bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32813bc9",
        "outputId": "c3988692-7c34-4fd9-855d-5948148b81d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "weighted_steps = np.ones(total_len)\n",
        "\n",
        "for start_idx in check[0]:\n",
        "    weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "67f56c9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67f56c9f",
        "outputId": "31a99f3b-57da-47c0-99ec-8a1be6ee5fd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 5,  6,  7,  8,  9, 10, 11, 12, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "        39]),)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "np.where(weighted_steps == 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0839f7a6",
      "metadata": {
        "id": "0839f7a6"
      },
      "source": [
        "### UPDATE: modified LIME segment (TODO, intergrate the updated version in LatentCF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "efdd6b6c",
      "metadata": {
        "id": "efdd6b6c"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "import stumpy\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.utils import check_random_state\n",
        "from fastdtw import fastdtw\n",
        "import random\n",
        "from explanations import NNSegment, RBP\n",
        "\n",
        "def LIMESegment(example, model, model_type='class', distance='dtw', n=100, window_size=None, cp=None, f=None, random_state=None):\n",
        "    random_state = check_random_state(random_state)\n",
        "    if window_size is None:\n",
        "        window_size =int(example.shape[0]/5)\n",
        "    if cp is None:\n",
        "        cp = 3\n",
        "    if f is None: \n",
        "        f = int(example.shape[0]/10)\n",
        "    \n",
        "    cp_indexes = NNSegment(example.reshape(example.shape[0]), window_size, cp)\n",
        "    segment_indexes = [0] + cp_indexes + [-1]\n",
        "    generated_samples_interpretable = [random_state.binomial(1, 0.5, len(cp_indexes)+1) for _ in range(0,n)] #UPDATE HERE\n",
        "    \n",
        "    generated_samples_raw = RBP(generated_samples_interpretable, example, segment_indexes, f)\n",
        "    sample_predictions = model.predict(generated_samples_raw)\n",
        "    \n",
        "#     print(np.argmax(sample_predictions, axis=1))\n",
        "\n",
        "    if model_type == 'proba':\n",
        "        y_labels = np.argmax(sample_predictions, axis=1)\n",
        "    elif isinstance(model_type, int): #UPDATE HERE\n",
        "        y_labels = sample_predictions[:, model_type]\n",
        "    else:\n",
        "        y_labels = sample_predictions\n",
        "    \n",
        "    if distance == 'dtw':\n",
        "        distances = np.asarray([fastdtw(example, sample)[0] for sample in generated_samples_raw])\n",
        "        weights = np.exp(-(np.abs((distances - np.mean(distances))/np.std(distances)).reshape(n,)))\n",
        "    elif distance == 'euclidean':\n",
        "        distances = np.asarray([np.linalg.norm(np.ones(len(cp_indexes)+1)-x) for x in generated_samples_interpretable])\n",
        "        weights = np.exp(-(np.abs(distances**2/0.75*(len(segment_indexes)**2)).reshape(n,)))\n",
        "\n",
        "    clf = Ridge(random_state=random_state) #UPDATE HERE\n",
        "    clf.fit(generated_samples_interpretable, y_labels, weights)\n",
        "\n",
        "    return clf.coef_, segment_indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5fe9328d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fe9328d",
        "outputId": "bd9c2176-390e-4f7e-db46-3e205a73ffda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.02058312, -0.37443078, -0.01305485,  0.52064166, -0.04373413,\n",
              "         0.15369393,  0.12898567, -0.16725209, -0.16731821, -0.04623422,\n",
              "        -0.07549762]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "explanations = LIMESegment(series, classifier, model_type=0, random_state=12, cp=10, window_size=10) # warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "explanations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dbb12d",
      "metadata": {
        "id": "f9dbb12d"
      },
      "source": [
        "## CF generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "496d7ac5",
      "metadata": {
        "id": "496d7ac5"
      },
      "outputs": [],
      "source": [
        "from _composite import extract_encoder_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "99221796",
      "metadata": {
        "id": "99221796"
      },
      "outputs": [],
      "source": [
        "class ModifiedLatentCF:\n",
        "    \"\"\"Explanations by generating a counterfacutal sample in the latent space of\n",
        "    any autoencoder.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Latent-CF: A Simple Baseline for Reverse Counterfactual Explanation\n",
        "        Rachana Balasubramanian and Samuel Sharpe and Brian Barr and Jason Wittenbach and C. Bayan Brus\n",
        "        In Proceedings of the Conference on Neural Information Processing Systems, 2020\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(    \n",
        "        self, \n",
        "        probability=0.5, \n",
        "        *, \n",
        "        alpha=0.001, \n",
        "        tolerance=1e-6, \n",
        "        learning_rate=1e-3, \n",
        "        max_iter=100,\n",
        "        optimizer=None,\n",
        "        autoencoder=None,\n",
        "        only_encoder=None,\n",
        "        only_decoder=None,\n",
        "        validity_loss_weight=1.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        probability : float, optional\n",
        "            The desired probability assigned by the model\n",
        "\n",
        "        alpha : float, optional\n",
        "            The step size\n",
        "\n",
        "        tolerance : float, optional\n",
        "            The maximum difference between the desired and assigned probability\n",
        "\n",
        "        learning_rate : float, optional\n",
        "            The learning rate of the optimizer\n",
        "\n",
        "        max_iter : int, optional\n",
        "            The maximum number of iterations\n",
        "\n",
        "        autoencoder : int, optional\n",
        "            The autoencoder for the latent representation\n",
        "\n",
        "            - if None the sample is generated in the original space\n",
        "            - if given, the autoencoder is expected to have `k` decoder layer and `k`\n",
        "              encoding layers.\n",
        "        \"\"\"\n",
        "        self.optimizer_ = tf.optimizers.Adam(learning_rate=1e-4) if optimizer is None else optimizer\n",
        "        self.mse_loss_ = keras.losses.MeanSquaredError() \n",
        "#         self.mae_loss_ = keras.losses.MeanAbsoluteError() \n",
        "        self.alpha_ = tf.constant(alpha)\n",
        "        self.probability_ = tf.constant(probability)\n",
        "        self.tolerance_ = tf.constant(tolerance)\n",
        "        self.max_iter = max_iter\n",
        "        self.autoencoder = autoencoder\n",
        "        self.only_encoder = only_encoder\n",
        "        self.only_decoder = only_decoder\n",
        "        \n",
        "        # Weights of the different loss components\n",
        "        self.validity_weight = validity_loss_weight\n",
        "        self.proximity_weight = (1 - self.validity_weight)\n",
        "\n",
        "    def fit(self, model):\n",
        "        \"\"\"Fit a new counterfactual explainer to the model\n",
        "\n",
        "        Paramaters\n",
        "        ----------\n",
        "\n",
        "        model : keras.Model\n",
        "            The model\n",
        "        \"\"\"\n",
        "        if self.autoencoder:\n",
        "            encode_input, encode_output, decode_input, decode_output = extract_encoder_decoder(self.autoencoder)\n",
        "            self.decoder_ = keras.Model(inputs=decode_input, outputs=decode_output)\n",
        "            self.encoder_ = keras.Model(inputs=encode_input, outputs=encode_output)\n",
        "        elif self.only_encoder and self.only_decoder:\n",
        "            self.encoder_ = self.only_encoder\n",
        "            self.decoder_ = self.only_decoder\n",
        "        else:\n",
        "            self.decoder_ = None\n",
        "            self.encoder_ = None\n",
        "        self.model_ = model\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Compute the differnece beteween the desired and actual probability\n",
        "\n",
        "        Paramters\n",
        "        ---------\n",
        "        x : Variable\n",
        "            Variable of the sample\n",
        "        \"\"\"\n",
        "        if self.autoencoder is None:\n",
        "            z = x\n",
        "        else:\n",
        "            z = self.decoder_(x)\n",
        "        \n",
        "        return self.model_(z)\n",
        "    \n",
        "    # TODO: add global weights in the function input?\n",
        "    def get_local_weights(self, input_sample):\n",
        "        local_explanation = LIMESegment(input_sample, self.model_, model_type='proba', cp=10, window_size=10)\n",
        "        \n",
        "        check = np.where(seg_imp <= -0.01) # TODO: decide the threshold, 0.01 or 0.1? seg_imp >= threshold or or <= -threshold???\n",
        "        weighted_steps = np.ones(total_len) # if weights are all one? => same as a normal MAE function\n",
        "        for start_idx in check[0]:\n",
        "            weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "        \n",
        "        weighted_steps = weighted_steps.reshape(1, n_timesteps_padded, 1) # need to reshape for multiplication in `tf.math.multiply()`\n",
        "        return weighted_steps\n",
        "    \n",
        "\n",
        "    # The \"validity_loss\" is designed to measure the prediction probability to the desired decision boundary\n",
        "    def validity_loss(self, prediction):\n",
        "        return self.mse_loss_(self.probability_, prediction) \n",
        "    \n",
        "    # An auxiliary MAE loss function to measure the proximity with step_weights\n",
        "    def weighted_mean_absolute_error(self, original_sample, cf_sample, step_weights):\n",
        "        return tf.math.reduce_mean(\n",
        "            tf.math.multiply(tf.math.abs(original_sample - cf_sample), step_weights)\n",
        "        )\n",
        "    \n",
        "    def compute_loss(self, original_sample, z_search, step_weights): # additional input of step_weights\n",
        "        # Initialize the loss\n",
        "        loss = tf.zeros(shape=())\n",
        "        decoded = self.decoder_(z_search)\n",
        "        pred = self.model_(decoded)\n",
        "        \n",
        "        # Add validity_loss \n",
        "        valid_loss = self.validity_loss(pred)\n",
        "        loss += self.validity_weight * valid_loss\n",
        "\n",
        "        # Add proximity_loss\n",
        "        proxi_loss = self.weighted_mean_absolute_error(\n",
        "            original_sample, decoded, step_weights=tf.cast(step_weights, tf.float32)) \n",
        "        loss += self.proximity_weight * proxi_loss\n",
        "\n",
        "        return loss, valid_loss, proxi_loss\n",
        "\n",
        "    # TODO: compatible with the counterfactuals of wildboar\n",
        "    #       i.e., define the desired output target per label\n",
        "    def transform(self, x):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        if self.only_encoder is not None: # if only encoder, then return the latent embeddings\n",
        "            _, encoded_dim1, encoded_dim2 = self.only_encoder.layers[-1].output_shape\n",
        "            result_samples = np.empty((x.shape[0], encoded_dim1, encoded_dim2)) \n",
        "        else: \n",
        "            result_samples = np.empty(x.shape)\n",
        "\n",
        "        losses = np.empty(x.shape[0])\n",
        "        for i in range(x.shape[0]):\n",
        "            if i % 50 == 0: print(f'{i} samples been transformed.')\n",
        "            \n",
        "            step_weights = self.get_local_weights(x[i])\n",
        "            x_sample, loss = self._transform_sample_z(x[np.newaxis, i], step_weights)\n",
        "\n",
        "            result_samples[i] = x_sample\n",
        "            losses[i] = loss\n",
        "\n",
        "        return result_samples, losses\n",
        "\n",
        "    def _transform_sample_z(self, x, step_weights):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        # TODO: check_is_fitted(self)\n",
        "        if self.only_encoder or self.autoencoder is not None:\n",
        "            z = tf.Variable(self.encoder_(x))\n",
        "        else:\n",
        "            z = tf.Variable(x, dtype=tf.float32)\n",
        "\n",
        "        it = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        # TODO: modify the loss to check both validity and proximity; how to design the condition here?\n",
        "        # while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ or proxi_loss > 0.001)\n",
        "        while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ ) and \\\n",
        "        (it < self.max_iter if self.max_iter else True):\n",
        "            # Get gradients of loss wrt the sample\n",
        "            grads = tape.gradient(loss, z)\n",
        "            # Update the weights of the sample\n",
        "            self.optimizer_.apply_gradients([(grads, z)])\n",
        "            \n",
        "            with tf.GradientTape() as tape:\n",
        "                loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            it += 1\n",
        "            pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        print(f'current valid: {valid_loss}, proxi: {proxi_loss}, pred prob:{pred}, iter: {it}.')\n",
        "  \n",
        "        return z.numpy() if self.autoencoder is None else self.decoder_(z).numpy(), float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "65d35a59",
      "metadata": {
        "id": "65d35a59"
      },
      "outputs": [],
      "source": [
        "## Evaluation metrics\n",
        "# use radius to find the count of points - KDTree; a trained tree is needed for evaluation\n",
        "tree = KDTree(\n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps), \n",
        "    leaf_size=40, metric='euclidean')\n",
        "max_distance = distance_matrix(\n",
        "    X_train_processed[y_train_classes==neg_label].reshape(-1, n_timesteps), \n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps)).max()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e21c3e55",
      "metadata": {
        "id": "e21c3e55"
      },
      "source": [
        "### loss weight: 0.01 valid + 0.99 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ec07ca78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec07ca78",
        "outputId": "a33a30c7-be20-4c88-dfd4-f8c3904a0bb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ModifiedLatentCF at 0x7fbf06ec1b20>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.01)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea532aa4",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea532aa4",
        "outputId": "08f642e0-be26-4044-90a4-8c1d890bae43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 13ms/step\n",
            "0 samples been transformed.\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "current valid: 0.25, proxi: 0.001699176267720759, pred prob:[[1.000000e+00 2.094302e-10]], iter: 100.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 3.3658707820904965e-08, proxi: 0.0014217367861419916, pred prob:[[0.49981654 0.50018346]], iter: 68.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 4.371779311895807e-07, proxi: 0.0013067370746284723, pred prob:[[0.4993388 0.5006612]], iter: 92.\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "current valid: 0.25, proxi: 0.0002844009140972048, pred prob:[[1.000000e+00 6.972483e-10]], iter: 100.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 1.4819846910540946e-05, proxi: 0.0007172743207775056, pred prob:[[0.4961503 0.5038496]], iter: 100.\n",
            "4/4 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab892e00",
      "metadata": {
        "id": "ab892e00"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d2b276",
      "metadata": {
        "id": "50d2b276"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c585862",
      "metadata": {
        "id": "1c585862"
      },
      "source": [
        "### loss weight: 0.25 valid + 0.75 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a562cb6c",
      "metadata": {
        "id": "a562cb6c"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.25)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bc5936",
      "metadata": {
        "scrolled": true,
        "id": "87bc5936"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ac4b98",
      "metadata": {
        "id": "22ac4b98"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1bdc3e",
      "metadata": {
        "id": "4b1bdc3e"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc58d89",
      "metadata": {
        "id": "5fc58d89"
      },
      "source": [
        "### loss weight: 0.5 valid + 0.5 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d43605",
      "metadata": {
        "id": "78d43605"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.5)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212f18fe",
      "metadata": {
        "scrolled": true,
        "id": "212f18fe"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e29f240",
      "metadata": {
        "id": "7e29f240"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23cd4f6",
      "metadata": {
        "id": "b23cd4f6"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae4b832",
      "metadata": {
        "id": "fae4b832"
      },
      "source": [
        "### loss weight: 0.75 valid + 0.25 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d0d1a",
      "metadata": {
        "id": "fe2d0d1a"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.75)\n",
        "\n",
        "cf_model.fit(classifier)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918280df",
      "metadata": {
        "id": "918280df"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18a50bb",
      "metadata": {
        "id": "c18a50bb"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fc9c86",
      "metadata": {
        "id": "73fc9c86"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac37578f",
      "metadata": {
        "id": "ac37578f"
      },
      "source": [
        "### loss weight: 1 valid + 0 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a555c820",
      "metadata": {
        "id": "a555c820"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=1.0)\n",
        "\n",
        "cf_model.fit(classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c1ce75",
      "metadata": {
        "scrolled": true,
        "id": "49c1ce75"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f6bf78",
      "metadata": {
        "id": "59f6bf78"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c73320",
      "metadata": {
        "id": "57c73320"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}