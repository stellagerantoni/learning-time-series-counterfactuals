{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "73286d25",
      "metadata": {
        "id": "73286d25",
        "outputId": "70d47cca-0e20-47df-964e-92d08fa8de9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learning-time-series-counterfactuals'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 155 (delta 88), reused 107 (delta 48), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (155/155), 1.48 MiB | 26.99 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "/content/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals\n"
          ]
        }
      ],
      "source": [
        " ! git clone https://github.com/stellagerantoni/learning-time-series-counterfactuals\n",
        " %cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e2d8f2dc",
      "metadata": {
        "id": "e2d8f2dc"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n",
        "!pip install -q wildboar\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e955a6e8",
      "metadata": {
        "id": "e955a6e8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./learning-time-series-counterfactuals/src')\n",
        "sys.path.append('./learning-time-series-counterfactuals/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307ebbad",
      "metadata": {
        "id": "307ebbad"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "da78e0e8",
      "metadata": {
        "id": "da78e0e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefd9897-daaf-4077-bc60-47cff45202af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/src\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "%cd src/\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                             find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bdac5a53",
      "metadata": {
        "id": "bdac5a53"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "79751faf",
      "metadata": {
        "id": "79751faf"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"TwoLeadECG\"\n",
        "OUTPUT_FILENAME = \"twolead-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "255ed3dc",
      "metadata": {
        "id": "255ed3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ce641f-7523-4e1b-be26-439404ecc879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading ucr-v1.0-default.zip (231.83 MB)\n",
            "  |██████████████████████████████████████████████████| 231.83/231.83 MB\n"
          ]
        }
      ],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = 2\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "398b9372",
      "metadata": {
        "id": "398b9372"
      },
      "outputs": [],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "logger.info(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2a9f72b9",
      "metadata": {
        "id": "2a9f72b9"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bf7b163a",
      "metadata": {
        "id": "bf7b163a",
        "outputId": "8f50fd0b-fcb3-449e-e970-7cd2232d5ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 14s 23ms/step - loss: 0.1719 - val_loss: 0.0260\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0102\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0049\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0026\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 9.3918e-04 - val_loss: 6.6902e-04\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 5.6153e-04 - val_loss: 4.5481e-04\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 4.1707e-04 - val_loss: 3.6230e-04\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 3.3045e-04 - val_loss: 2.9444e-04\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.6627e-04 - val_loss: 2.2883e-04\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.1955e-04 - val_loss: 1.9838e-04\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8939e-04 - val_loss: 1.7480e-04\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.6734e-04 - val_loss: 1.5872e-04\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.5190e-04 - val_loss: 1.4347e-04\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4147e-04 - val_loss: 1.3274e-04\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3025e-04 - val_loss: 1.2291e-04\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.1927e-04 - val_loss: 1.1894e-04\n"
          ]
        }
      ],
      "source": [
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.1 1dCNN autoencoder + 1dCNN classifier\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\") \n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded, \n",
        "    X_train_processed_padded, \n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True, \n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "logger.info(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "85274cc7",
      "metadata": {
        "id": "85274cc7"
      },
      "outputs": [],
      "source": [
        "def Classifier(n_timesteps, n_features, n_output=2, n_conv_layers=1, add_dense_layer=True):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "    inputs = keras.Input(shape=(n_timesteps, n_features), dtype=\"float32\")\n",
        "    \n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128)(inputs)\n",
        "    else: \n",
        "        x = inputs\n",
        "    \n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(n_output, activation='softmax')(x)\n",
        "    classifier = keras.Model(inputs, outputs)\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "81b59010",
      "metadata": {
        "scrolled": true,
        "id": "81b59010",
        "outputId": "63f63bee-fb8b-41c8-85ac-e27e35615aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 4s 26ms/step - loss: 0.6109 - accuracy: 0.6957 - val_loss: 0.7348 - val_accuracy: 0.4979\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.9118 - val_loss: 0.8685 - val_accuracy: 0.4979\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.9387 - val_loss: 0.9350 - val_accuracy: 0.4979\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.9774 - val_loss: 0.9009 - val_accuracy: 0.4979\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1757 - accuracy: 0.9839 - val_loss: 0.8770 - val_accuracy: 0.4979\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9914 - val_loss: 0.7918 - val_accuracy: 0.5021\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1098 - accuracy: 0.9892 - val_loss: 0.7037 - val_accuracy: 0.5408\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9925 - val_loss: 0.4745 - val_accuracy: 0.7597\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9946 - val_loss: 0.3686 - val_accuracy: 0.8670\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9935 - val_loss: 0.2957 - val_accuracy: 0.8541\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9925 - val_loss: 0.2391 - val_accuracy: 0.9056\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9925 - val_loss: 0.2273 - val_accuracy: 0.9185\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9978 - val_loss: 0.1748 - val_accuracy: 0.9313\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9968 - val_loss: 0.1569 - val_accuracy: 0.9571\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9978 - val_loss: 0.1421 - val_accuracy: 0.9485\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9968 - val_loss: 0.1247 - val_accuracy: 0.9657\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9968 - val_loss: 0.1983 - val_accuracy: 0.9056\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9914 - val_loss: 0.1021 - val_accuracy: 0.9785\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 0.1747 - val_accuracy: 0.9227\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9989 - val_loss: 0.0904 - val_accuracy: 0.9700\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9978 - val_loss: 0.0955 - val_accuracy: 0.9742\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9785\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9871\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9968 - val_loss: 0.1684 - val_accuracy: 0.9142\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9957\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9989 - val_loss: 0.0351 - val_accuracy: 0.9957\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9528\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 0.0956 - val_accuracy: 0.9657\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9989 - val_loss: 0.0462 - val_accuracy: 0.9871\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9957\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9828\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9957\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9871\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9871\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9185\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9828\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9914\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9957\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9957\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9957\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9957\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9957\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9957\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9957\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.8841\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9957\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9957\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9957\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9957\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9914\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9871\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "shallow_cnn = True\n",
        "# ### 1dCNN classifier\n",
        "if shallow_cnn == True:\n",
        "    logger.info(f\"Check shallow_cnn argument={shallow_cnn}, use the shallow structure.\")\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=1, add_dense_layer=True) # shallow CNN for small data size\n",
        "else:\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=3, add_dense_layer=False) # deeper CNN layers for data with larger size\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN classifier:\")\n",
        "classifier_history = classifier.fit(X_train_processed_padded, \n",
        "        y_train, \n",
        "        epochs=150,\n",
        "        batch_size=32,\n",
        "        shuffle=True, \n",
        "        verbose=True, \n",
        "        validation_data=(X_test_processed_padded, y_test),\n",
        "        callbacks=[early_stopping_accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3f69f78d",
      "metadata": {
        "id": "3f69f78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "b422aa07-b0bd-4737-cc37-cfcd87ea53d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Pred:pos  Pred:neg\n",
              "True:pos       117         0\n",
              "True:neg         0       116"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fd2cfef-6579-4036-9976-bda512742e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred:pos</th>\n",
              "      <th>Pred:neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True:pos</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True:neg</th>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fd2cfef-6579-4036-9976-bda512742e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fd2cfef-6579-4036-9976-bda512742e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fd2cfef-6579-4036-9976-bda512742e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "# y_pred_classes = np.array([1 if pred > 0.5 else 0 for pred in y_pred])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "logger.info(f\"1dCNN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "        confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "        index=['True:pos', 'True:neg'], \n",
        "        columns=['Pred:pos', 'Pred:neg']\n",
        "    )\n",
        "confusion_matrix_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c159d8",
      "metadata": {
        "id": "e2c159d8"
      },
      "source": [
        "## Get LIME local weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f7ddba00",
      "metadata": {
        "id": "f7ddba00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b60dc91-099b-4e22-fd8f-aa26cfb31868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals/learning-time-series-counterfactuals/src/learning-time-series-counterfactuals/src/LIMESegment/Utils\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../LIMESegment/Utils/')\n",
        "%cd LIMESegment/Utils/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "523baa28",
      "metadata": {
        "id": "523baa28"
      },
      "outputs": [],
      "source": [
        "from explanations import LIMESegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f59a1c92",
      "metadata": {
        "id": "f59a1c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fe32e5-6dd6-4667-9848-d19223f7facf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "idx = 2 # explained instance\n",
        "series = X_test_processed_padded[idx]\n",
        "print(y_pred_classes[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0618da3b",
      "metadata": {
        "id": "0618da3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a66b48-889e-46f0-9cef-fcfc77d6afa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.04538273,  0.52995128,  0.00221285, -0.37590307,  0.0444214 ,\n",
              "        -0.12282846, -0.13230288,  0.02226997, -0.00315427, -0.02098125,\n",
              "        -0.05524347]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\"\"\"\n",
        "# parameters\n",
        "ts: TS array of shape T x 1 where T is length of time series\n",
        "model: Trained model on dataset array of shape n x T x 1\n",
        "model_type: String indicating if classificaton model produces binary output \"class\" or probability output \"proba\", default \"class\"\n",
        "distance: Distance metric to be used by LIMESegment default is 'dtw'\n",
        "window_size: Window size to be used by NNSegment default is T/5\n",
        "cp: Number of change points to be determinded by NNSegment default is 3\n",
        "f: Frequency parameter for RBP default is T/10\n",
        "\"\"\"\n",
        "\n",
        "explanations = LIMESegment(series, classifier, model_type='proba', cp=10, window_size=10)\n",
        "explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "188b89bb",
      "metadata": {
        "id": "188b89bb"
      },
      "outputs": [],
      "source": [
        "seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "56c277ac",
      "metadata": {
        "id": "56c277ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78684617-85ac-4004-dbe9-b7b62119e61c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "series.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b22c925a",
      "metadata": {
        "id": "b22c925a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "0e84ec42-a15a-41fb-c389-f6d49534e1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0, 5: -0.045382732632395284\n",
            "5, 13: 0.5299512809570422\n",
            "13, 19: 0.0022128462959168874\n",
            "19, 30: -0.37590307367294873\n",
            "30, 40: 0.044421397025548516\n",
            "40, 48: -0.12282845716530598\n",
            "48, 53: -0.13230287627956783\n",
            "53, 58: 0.022269974101997967\n",
            "58, 66: -0.003154265426657954\n",
            "66, 72: -0.020981246036535704\n",
            "72, 84: -0.05524347013156295\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "plt.plot(series, color='b', label='Explained instance')\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "plt.legend(loc='lower left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    color = 'red' if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "74485f03",
      "metadata": {
        "id": "74485f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c6bbbd-a68e-4f40-fe99-1b0d875b6c56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "check = np.where(seg_imp >= 0.01) # seg_imp >= 0.01 or 0.1\n",
        "check[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "32813bc9",
      "metadata": {
        "id": "32813bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f552da4b-b33f-40b9-93a3-5c6be74069a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "weighted_steps = np.ones(total_len)\n",
        "\n",
        "for start_idx in check[0]:\n",
        "    weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "67f56c9f",
      "metadata": {
        "id": "67f56c9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8889d564-1ad1-4f5d-c858-aa4a6c6c1851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 5,  6,  7,  8,  9, 10, 11, 12, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "        39, 53, 54, 55, 56, 57]),)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "np.where(weighted_steps == 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0839f7a6",
      "metadata": {
        "id": "0839f7a6"
      },
      "source": [
        "### UPDATE: modified LIME segment (TODO, intergrate the updated version in LatentCF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "efdd6b6c",
      "metadata": {
        "id": "efdd6b6c"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "import stumpy\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.utils import check_random_state\n",
        "from fastdtw import fastdtw\n",
        "import random\n",
        "from explanations import NNSegment, RBP\n",
        "\n",
        "def LIMESegment(example, model, model_type='class', distance='dtw', n=100, window_size=None, cp=None, f=None, random_state=None):\n",
        "    random_state = check_random_state(random_state)\n",
        "    if window_size is None:\n",
        "        window_size =int(example.shape[0]/5)\n",
        "    if cp is None:\n",
        "        cp = 3\n",
        "    if f is None: \n",
        "        f = int(example.shape[0]/10)\n",
        "    \n",
        "    cp_indexes = NNSegment(example.reshape(example.shape[0]), window_size, cp)\n",
        "    segment_indexes = [0] + cp_indexes + [-1]\n",
        "    generated_samples_interpretable = [random_state.binomial(1, 0.5, len(cp_indexes)+1) for _ in range(0,n)] #UPDATE HERE\n",
        "    \n",
        "    generated_samples_raw = RBP(generated_samples_interpretable, example, segment_indexes, f)\n",
        "    sample_predictions = model.predict(generated_samples_raw)\n",
        "    \n",
        "#     print(np.argmax(sample_predictions, axis=1))\n",
        "\n",
        "    if model_type == 'proba':\n",
        "        y_labels = np.argmax(sample_predictions, axis=1)\n",
        "    elif isinstance(model_type, int): #UPDATE HERE\n",
        "        y_labels = sample_predictions[:, model_type]\n",
        "    else:\n",
        "        y_labels = sample_predictions\n",
        "    \n",
        "    if distance == 'dtw':\n",
        "        distances = np.asarray([fastdtw(example, sample)[0] for sample in generated_samples_raw])\n",
        "        weights = np.exp(-(np.abs((distances - np.mean(distances))/np.std(distances)).reshape(n,)))\n",
        "    elif distance == 'euclidean':\n",
        "        distances = np.asarray([np.linalg.norm(np.ones(len(cp_indexes)+1)-x) for x in generated_samples_interpretable])\n",
        "        weights = np.exp(-(np.abs(distances**2/0.75*(len(segment_indexes)**2)).reshape(n,)))\n",
        "\n",
        "    clf = Ridge(random_state=random_state) #UPDATE HERE\n",
        "    clf.fit(generated_samples_interpretable, y_labels, weights)\n",
        "\n",
        "    return clf.coef_, segment_indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5fe9328d",
      "metadata": {
        "id": "5fe9328d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae0a4d0-092c-407e-fdb7-a8e36132d016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.00688106, -0.38401519,  0.00056556,  0.51695885, -0.03967784,\n",
              "         0.1415558 ,  0.1153369 , -0.17947492, -0.1656883 , -0.05779254,\n",
              "        -0.06646668]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "explanations = LIMESegment(series, classifier, model_type=0, random_state=12, cp=10, window_size=10) # warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "explanations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dbb12d",
      "metadata": {
        "id": "f9dbb12d"
      },
      "source": [
        "## CF generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "496d7ac5",
      "metadata": {
        "id": "496d7ac5"
      },
      "outputs": [],
      "source": [
        "from _composite import extract_encoder_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "99221796",
      "metadata": {
        "id": "99221796"
      },
      "outputs": [],
      "source": [
        "class ModifiedLatentCF:\n",
        "    \"\"\"Explanations by generating a counterfacutal sample in the latent space of\n",
        "    any autoencoder.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Latent-CF: A Simple Baseline for Reverse Counterfactual Explanation\n",
        "        Rachana Balasubramanian and Samuel Sharpe and Brian Barr and Jason Wittenbach and C. Bayan Brus\n",
        "        In Proceedings of the Conference on Neural Information Processing Systems, 2020\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(    \n",
        "        self, \n",
        "        probability=0.5, \n",
        "        *, \n",
        "        alpha=0.001, \n",
        "        tolerance=1e-6, \n",
        "        learning_rate=1e-3, \n",
        "        max_iter=100,\n",
        "        optimizer=None,\n",
        "        autoencoder=None,\n",
        "        only_encoder=None,\n",
        "        only_decoder=None,\n",
        "        validity_loss_weight=1.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        probability : float, optional\n",
        "            The desired probability assigned by the model\n",
        "\n",
        "        alpha : float, optional\n",
        "            The step size\n",
        "\n",
        "        tolerance : float, optional\n",
        "            The maximum difference between the desired and assigned probability\n",
        "\n",
        "        learning_rate : float, optional\n",
        "            The learning rate of the optimizer\n",
        "\n",
        "        max_iter : int, optional\n",
        "            The maximum number of iterations\n",
        "\n",
        "        autoencoder : int, optional\n",
        "            The autoencoder for the latent representation\n",
        "\n",
        "            - if None the sample is generated in the original space\n",
        "            - if given, the autoencoder is expected to have `k` decoder layer and `k`\n",
        "              encoding layers.\n",
        "        \"\"\"\n",
        "        self.optimizer_ = tf.optimizers.Adam(learning_rate=1e-4) if optimizer is None else optimizer\n",
        "        self.mse_loss_ = keras.losses.MeanSquaredError() \n",
        "#         self.mae_loss_ = keras.losses.MeanAbsoluteError() \n",
        "        self.alpha_ = tf.constant(alpha)\n",
        "        self.probability_ = tf.constant(probability)\n",
        "        self.tolerance_ = tf.constant(tolerance)\n",
        "        self.max_iter = max_iter\n",
        "        self.autoencoder = autoencoder\n",
        "        self.only_encoder = only_encoder\n",
        "        self.only_decoder = only_decoder\n",
        "        \n",
        "        # Weights of the different loss components\n",
        "        self.validity_weight = validity_loss_weight\n",
        "        self.proximity_weight = (1 - self.validity_weight)\n",
        "\n",
        "    def fit(self, model):\n",
        "        \"\"\"Fit a new counterfactual explainer to the model\n",
        "\n",
        "        Paramaters\n",
        "        ----------\n",
        "\n",
        "        model : keras.Model\n",
        "            The model\n",
        "        \"\"\"\n",
        "        if self.autoencoder:\n",
        "            encode_input, encode_output, decode_input, decode_output = extract_encoder_decoder(self.autoencoder)\n",
        "            self.decoder_ = keras.Model(inputs=decode_input, outputs=decode_output)\n",
        "            self.encoder_ = keras.Model(inputs=encode_input, outputs=encode_output)\n",
        "        elif self.only_encoder and self.only_decoder:\n",
        "            self.encoder_ = self.only_encoder\n",
        "            self.decoder_ = self.only_decoder\n",
        "        else:\n",
        "            self.decoder_ = None\n",
        "            self.encoder_ = None\n",
        "        self.model_ = model\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Compute the differnece beteween the desired and actual probability\n",
        "\n",
        "        Paramters\n",
        "        ---------\n",
        "        x : Variable\n",
        "            Variable of the sample\n",
        "        \"\"\"\n",
        "        if self.autoencoder is None:\n",
        "            z = x\n",
        "        else:\n",
        "            z = self.decoder_(x)\n",
        "        \n",
        "        return self.model_(z)\n",
        "    \n",
        "    # TODO: add global weights in the function input?\n",
        "    def get_local_weights(self, input_sample):\n",
        "        local_explanation = LIMESegment(input_sample, self.model_, model_type='proba', cp=10, window_size=10)\n",
        "        \n",
        "        check = np.where(seg_imp <= -0.01) # TODO: decide the threshold, 0.01 or 0.1? seg_imp >= threshold or or <= -threshold???\n",
        "        weighted_steps = np.ones(total_len) # if weights are all one? => same as a normal MAE function\n",
        "        for start_idx in check[0]:\n",
        "            weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "        \n",
        "        weighted_steps = weighted_steps.reshape(1, n_timesteps_padded, 1) # need to reshape for multiplication in `tf.math.multiply()`\n",
        "        return weighted_steps\n",
        "    \n",
        "\n",
        "    # The \"validity_loss\" is designed to measure the prediction probability to the desired decision boundary\n",
        "    def validity_loss(self, prediction):\n",
        "        return self.mse_loss_(self.probability_, prediction) \n",
        "    \n",
        "    # An auxiliary MAE loss function to measure the proximity with step_weights\n",
        "    def weighted_mean_absolute_error(self, original_sample, cf_sample, step_weights):\n",
        "        return tf.math.reduce_mean(\n",
        "            tf.math.multiply(tf.math.abs(original_sample - cf_sample), step_weights)\n",
        "        )\n",
        "    \n",
        "    def compute_loss(self, original_sample, z_search, step_weights): # additional input of step_weights\n",
        "        # Initialize the loss\n",
        "        loss = tf.zeros(shape=())\n",
        "        decoded = self.decoder_(z_search)\n",
        "        pred = self.model_(decoded)\n",
        "        \n",
        "        # Add validity_loss \n",
        "        valid_loss = self.validity_loss(pred)\n",
        "        loss += self.validity_weight * valid_loss\n",
        "\n",
        "        # Add proximity_loss\n",
        "        proxi_loss = self.weighted_mean_absolute_error(\n",
        "            original_sample, decoded, step_weights=tf.cast(step_weights, tf.float32)) \n",
        "        loss += self.proximity_weight * proxi_loss\n",
        "\n",
        "        return loss, valid_loss, proxi_loss\n",
        "\n",
        "    # TODO: compatible with the counterfactuals of wildboar\n",
        "    #       i.e., define the desired output target per label\n",
        "    def transform(self, x):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        if self.only_encoder is not None: # if only encoder, then return the latent embeddings\n",
        "            _, encoded_dim1, encoded_dim2 = self.only_encoder.layers[-1].output_shape\n",
        "            result_samples = np.empty((x.shape[0], encoded_dim1, encoded_dim2)) \n",
        "        else: \n",
        "            result_samples = np.empty(x.shape)\n",
        "\n",
        "        losses = np.empty(x.shape[0])\n",
        "        for i in range(x.shape[0]):\n",
        "            if i % 50 == 0: print(f'{i} samples been transformed.')\n",
        "            \n",
        "            step_weights = self.get_local_weights(x[i])\n",
        "            x_sample, loss = self._transform_sample_z(x[np.newaxis, i], step_weights)\n",
        "\n",
        "            result_samples[i] = x_sample\n",
        "            losses[i] = loss\n",
        "\n",
        "        return result_samples, losses\n",
        "\n",
        "    def _transform_sample_z(self, x, step_weights):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        # TODO: check_is_fitted(self)\n",
        "        if self.only_encoder or self.autoencoder is not None:\n",
        "            z = tf.Variable(self.encoder_(x))\n",
        "        else:\n",
        "            z = tf.Variable(x, dtype=tf.float32)\n",
        "\n",
        "        it = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        # TODO: modify the loss to check both validity and proximity; how to design the condition here?\n",
        "        # while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ or proxi_loss > 0.001)\n",
        "        while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ ) and \\\n",
        "        (it < self.max_iter if self.max_iter else True):\n",
        "            # Get gradients of loss wrt the sample\n",
        "            grads = tape.gradient(loss, z)\n",
        "            # Update the weights of the sample\n",
        "            self.optimizer_.apply_gradients([(grads, z)])\n",
        "            \n",
        "            with tf.GradientTape() as tape:\n",
        "                loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            it += 1\n",
        "            pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        print(f'current valid: {valid_loss}, proxi: {proxi_loss}, pred prob:{pred}, iter: {it}.')\n",
        "  \n",
        "        return z.numpy() if self.autoencoder is None else self.decoder_(z).numpy(), float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "65d35a59",
      "metadata": {
        "id": "65d35a59"
      },
      "outputs": [],
      "source": [
        "## Evaluation metrics\n",
        "# use radius to find the count of points - KDTree; a trained tree is needed for evaluation\n",
        "tree = KDTree(\n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps), \n",
        "    leaf_size=40, metric='euclidean')\n",
        "max_distance = distance_matrix(\n",
        "    X_train_processed[y_train_classes==neg_label].reshape(-1, n_timesteps), \n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps)).max()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e21c3e55",
      "metadata": {
        "id": "e21c3e55"
      },
      "source": [
        "### loss weight: 0.01 valid + 0.99 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ec07ca78",
      "metadata": {
        "id": "ec07ca78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a93b21-0b49-4c4d-f8a9-13b292ff018c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ModifiedLatentCF at 0x7fdc4742e6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.01)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea532aa4",
      "metadata": {
        "scrolled": true,
        "id": "ea532aa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd7e257-d02c-4223-cbda-65abdc69fc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            "0 samples been transformed.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 0.25, proxi: 0.00152695516590029, pred prob:[[1.0000000e+00 8.5677784e-11]], iter: 100.\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "current valid: 4.2956813217642775e-08, proxi: 0.0016514702001586556, pred prob:[[0.49979272 0.50020725]], iter: 62.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.0007611821638420224, proxi: 0.0012566825607791543, pred prob:[[0.47241044 0.5275895 ]], iter: 100.\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "current valid: 0.25, proxi: 0.00033220701152458787, pred prob:[[1.0000000e+00 3.7630756e-09]], iter: 100.\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "current valid: 1.653664316592085e-09, proxi: 0.000848194700665772, pred prob:[[0.49995932 0.50004065]], iter: 58.\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "current valid: 3.9407774465871626e-07, proxi: 0.0012529018567875028, pred prob:[[0.49937224 0.50062776]], iter: 45.\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "current valid: 9.615192766432301e-07, proxi: 0.0015054771210998297, pred prob:[[0.4990194  0.50098056]], iter: 48.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 7.60769438556963e-08, proxi: 0.001628475496545434, pred prob:[[0.4997242  0.50027585]], iter: 69.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.25, proxi: 0.0009569903486408293, pred prob:[[1.000000e+00 6.612066e-09]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 4.379473139692891e-08, proxi: 0.0008883685804903507, pred prob:[[0.49979073 0.5002093 ]], iter: 80.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.24994155764579773, proxi: 0.0006009328062646091, pred prob:[[9.9994159e-01 5.8466747e-05]], iter: 100.\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "current valid: 5.935237368248636e-07, proxi: 0.000734371249563992, pred prob:[[0.49922958 0.5007704 ]], iter: 47.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.2499995231628418, proxi: 0.0007113871397450566, pred prob:[[9.9999952e-01 4.6587206e-07]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.00010956386540783569, proxi: 0.0002446603903081268, pred prob:[[0.48953274 0.5104673 ]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 8.171779199983575e-07, proxi: 0.0005214808625169098, pred prob:[[0.499096   0.50090396]], iter: 61.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.00036292814183980227, proxi: 0.0004267702461220324, pred prob:[[0.4809493  0.51905066]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 2.8296193477217457e-07, proxi: 0.00029906933195888996, pred prob:[[0.49946803 0.5005319 ]], iter: 91.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 4.093392362847226e-07, proxi: 0.0006934072589501739, pred prob:[[0.4993602 0.5006398]], iter: 56.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 5.185420377529226e-07, proxi: 0.0013401838950812817, pred prob:[[0.4992799 0.5007201]], iter: 45.\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "current valid: 4.984179895473062e-07, proxi: 0.0016412115655839443, pred prob:[[0.49929404 0.500706  ]], iter: 41.\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "current valid: 7.416358585032867e-07, proxi: 0.0004756328125949949, pred prob:[[0.4991388  0.50086117]], iter: 70.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.019444134086370468, proxi: 0.0005107139004394412, pred prob:[[0.6394422  0.36055776]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 3.607636074320908e-07, proxi: 0.0002433749905321747, pred prob:[[0.49939936 0.50060064]], iter: 70.\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "current valid: 3.9043800370563986e-07, proxi: 0.001722788205370307, pred prob:[[0.49937513 0.50062484]], iter: 43.\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "current valid: 3.065807447910629e-07, proxi: 0.0003922147152479738, pred prob:[[0.49944627 0.50055367]], iter: 98.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 0.0003004050231538713, proxi: 0.00017274082347285002, pred prob:[[0.5173322 0.4826678]], iter: 100.\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "current valid: 0.00036396674113348126, proxi: 0.00047621416160836816, pred prob:[[0.5190779  0.48092207]], iter: 100.\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "current valid: 4.905820105705061e-08, proxi: 0.0005278622847981751, pred prob:[[0.4997785 0.5002215]], iter: 55.\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab892e00",
      "metadata": {
        "id": "ab892e00"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d2b276",
      "metadata": {
        "id": "50d2b276"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c585862",
      "metadata": {
        "id": "1c585862"
      },
      "source": [
        "### loss weight: 0.25 valid + 0.75 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a562cb6c",
      "metadata": {
        "id": "a562cb6c"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.25)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bc5936",
      "metadata": {
        "scrolled": true,
        "id": "87bc5936"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ac4b98",
      "metadata": {
        "id": "22ac4b98"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1bdc3e",
      "metadata": {
        "id": "4b1bdc3e"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc58d89",
      "metadata": {
        "id": "5fc58d89"
      },
      "source": [
        "### loss weight: 0.5 valid + 0.5 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d43605",
      "metadata": {
        "id": "78d43605"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.5)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212f18fe",
      "metadata": {
        "scrolled": true,
        "id": "212f18fe"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e29f240",
      "metadata": {
        "id": "7e29f240"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23cd4f6",
      "metadata": {
        "id": "b23cd4f6"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae4b832",
      "metadata": {
        "id": "fae4b832"
      },
      "source": [
        "### loss weight: 0.75 valid + 0.25 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d0d1a",
      "metadata": {
        "id": "fe2d0d1a"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.75)\n",
        "\n",
        "cf_model.fit(classifier)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918280df",
      "metadata": {
        "id": "918280df"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18a50bb",
      "metadata": {
        "id": "c18a50bb"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fc9c86",
      "metadata": {
        "id": "73fc9c86"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac37578f",
      "metadata": {
        "id": "ac37578f"
      },
      "source": [
        "### loss weight: 1 valid + 0 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a555c820",
      "metadata": {
        "id": "a555c820"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=1.0)\n",
        "\n",
        "cf_model.fit(classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c1ce75",
      "metadata": {
        "scrolled": true,
        "id": "49c1ce75"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f6bf78",
      "metadata": {
        "id": "59f6bf78"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c73320",
      "metadata": {
        "id": "57c73320"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}